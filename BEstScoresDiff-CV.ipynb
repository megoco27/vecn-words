{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to reload files that are changed automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils file - contains some useful functions\n",
    "import quora_dup_utils as qu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters: file names and number of questions to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# files names - if these files and folders don't exist then they are downloaded \n",
    "raw_file_name = \"quora_duplicate_questions.tsv\"\n",
    "q1_file_name = \"cleaned_q1.txt\"\n",
    "q2_file_name = \"cleaned_q2.txt\"\n",
    "dup_file_name = \"is_duplicate.txt\"\n",
    "complete_data_dataframe = \"complete_data_dataframe.csv\"\n",
    "questions_folder_name = \"cleaned_data\"\n",
    "google_model_path = '/Users/megoconnell/Documents/Courses/Independent Study/RNNs/GoogleNews-vectors-negative300.bin' # path to saved Google word2vec model\n",
    "\n",
    "raw_file_name2 = \"quora_duplicate_questions2.tsv\"\n",
    "q1_file_name2 = \"2cleaned_q1.txt\"\n",
    "q2_file_name2 = \"2cleaned_q2.txt\"\n",
    "dup_file_name2 = \"2is_duplicate.txt\"\n",
    "complete_data_dataframe2 = \"2complete_data_dataframe.csv\"\n",
    "questions_folder_name2 = \"2cleaned_data\"\n",
    "\n",
    "# file to store doc2vec hyperparameters and ROC AUC errors\n",
    "parameters_and_errors_name = \"parameters_and_errors.csv\"\n",
    "parameters_and_errors_name2 = \"2parameters_and_errors.csv\"\n",
    "\n",
    "\n",
    "# number of question pairs to use in training doc2vec\n",
    "# total number of pairs is currently 404288\n",
    "num_question_pairs = 404288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>fold_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29630</td>\n",
       "      <td>30185</td>\n",
       "      <td>30187</td>\n",
       "      <td>b'On average, how predictable is each of the f...</td>\n",
       "      <td>b'On average, how predictable is each of the f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id   qid1   qid2  \\\n",
       "0           0  29630  30185  30187   \n",
       "\n",
       "                                           question1  \\\n",
       "0  b'On average, how predictable is each of the f...   \n",
       "\n",
       "                                           question2  is_duplicate  fold_id  \n",
       "0  b'On average, how predictable is each of the f...             1      0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and prepare gensim-friendly files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import requests\n",
    "\n",
    "    # DATA CLEANING WITH PANDAS\n",
    "    \n",
    "    # read in file into dataframe\n",
    "data = pd.read_csv('Item_Item_Diff_Paper.csv', sep='\\t')\n",
    "\n",
    "    # drop rows with null value\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "train = data.loc[data['fold_id']<4.0]\n",
    "test = data.loc[data['fold_id']==4.0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file with 100424 rows at quora_duplicate_questions.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # make columns of lower cased words\n",
    "train[\"cleaned_q1\"] = train['question1'].str.lower()\n",
    "train[\"cleaned_q2\"] = train['question2'].str.lower()\n",
    "    # remove punctuation from lower-cased words columns\n",
    "train['cleaned_q1'] = train['cleaned_q1'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "train['cleaned_q2'] = train['cleaned_q2'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "    # remove the character \"\\n\", which messes up the line delimiters in txt file\n",
    "    # these only occur ~20 times in the questions\n",
    "train[\"cleaned_q1\"] = train['cleaned_q1'].str.replace(\"\\n\", \"\")\n",
    "train[\"cleaned_q2\"] = train['cleaned_q2'].str.replace(\"\\n\", \"\")\n",
    "    # shuffle data before writing to file - this way random sample can be taken from file \n",
    "    # simply by choosing first n rows of file\n",
    "train = train.sample(frac=1)\n",
    "\n",
    "    # create directory to hold question data\n",
    "if not os.path.exists(questions_folder_name):\n",
    "    os.makedirs(questions_folder_name)\n",
    "\n",
    "    # write cleaned text rows to txt files, one line for each sentence\n",
    "train[\"cleaned_q1\"].to_csv(questions_folder_name + \"/\" + q1_file_name, sep='\\n', header=False, index=False)\n",
    "train[\"cleaned_q2\"].to_csv(questions_folder_name + \"/\" + q2_file_name, sep='\\n', header=False, index=False)\n",
    "    # write dup values to txt file, one line for each value\n",
    "train[\"is_duplicate\"].to_csv(dup_file_name, sep='\\n', header=False, index=False)\n",
    "    # write complete cleaning dataframe to text files as well - this can be reloaded \n",
    "    # to look at raw questions that get misclassified, etc.\n",
    "train.to_csv(complete_data_dataframe, sep=',', header=True, index=False)\n",
    "\n",
    "print (\"Saved file with\", len(data), \"rows at\", raw_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file with 100424 rows at quora_duplicate_questions2.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # make columns of lower cased words\n",
    "test[\"cleaned_q1\"] = test['question1'].str.lower()\n",
    "test[\"cleaned_q2\"] = test['question2'].str.lower()\n",
    "    # remove punctuation from lower-cased words columns\n",
    "test['cleaned_q1'] = test['cleaned_q1'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "test['cleaned_q2'] = test['cleaned_q2'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "    # remove the character \"\\n\", which messes up the line delimiters in txt file\n",
    "    # these only occur ~20 times in the questions\n",
    "test[\"cleaned_q1\"] = test['cleaned_q1'].str.replace(\"\\n\", \"\")\n",
    "test[\"cleaned_q2\"] = test['cleaned_q2'].str.replace(\"\\n\", \"\")\n",
    "    # shuffle data before writing to file - this way random sample can be taken from file \n",
    "    # simply by choosing first n rows of file\n",
    "test = test.sample(frac=1)\n",
    "\n",
    "    # create directory to hold question data\n",
    "if not os.path.exists(questions_folder_name2):\n",
    "    os.makedirs(questions_folder_name2)\n",
    "\n",
    "    # write cleaned text rows to txt files, one line for each sentence\n",
    "test[\"cleaned_q1\"].to_csv(questions_folder_name2 + \"/\" + q1_file_name2, sep='\\n', header=False, index=False)\n",
    "test[\"cleaned_q2\"].to_csv(questions_folder_name2 + \"/\" + q2_file_name2, sep='\\n', header=False, index=False)\n",
    "    # write dup values to txt file, one line for each value\n",
    "test[\"is_duplicate\"].to_csv(dup_file_name2, sep='\\n', header=False, index=False)\n",
    "    # write complete cleaning dataframe to text files as well - this can be reloaded \n",
    "    # to look at raw questions that get misclassified, etc.\n",
    "test.to_csv(complete_data_dataframe2, sep=',', header=True, index=False)\n",
    "\n",
    "print (\"Saved file with\", len(data), \"rows at\", raw_file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "# class that iterates through first \"rows\" lines of questions list (\"rows\" is integer)\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, dirname, rows=None):\n",
    "        self.dirname = dirname\n",
    "        self.rows = rows\n",
    "    def __iter__(self):\n",
    "        for filename in os.listdir(self.dirname):\n",
    "            for uid, text_line in enumerate(open(os.path.join(self.dirname, filename))):\n",
    "                if self.rows:\n",
    "                    if uid >= self.rows: \n",
    "                        break\n",
    "            # for uid, line in enumerate(open(os.path.join(self.dirname, filename))):\n",
    "                yield gensim.models.doc2vec.LabeledSentence(words=text_line.split(), tags=[os.path.basename(filename) + '_%s' % uid])\n",
    "\n",
    "# make sure using fast version\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1\n",
    "cores = multiprocessing.cpu_count() # number of cores on computer to use for computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404288 question pairs to train (160680 documents total)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data into memory - all data combined should only be 200-300 megabytes\n",
    "# this is done instead of using iterator - makes doing shuffles of data easier\n",
    "\n",
    "all_docs = []\n",
    "sentences = LabeledLineSentence(questions_folder_name, rows=num_question_pairs)\n",
    "for sentence in sentences:\n",
    "    all_docs.append(sentence)\n",
    "\n",
    "print('%d question pairs to train (%d documents total)' % (num_question_pairs, len(all_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404288 question pairs to train (160680 documents total)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data into memory - all data combined should only be 200-300 megabytes\n",
    "# this is done instead of using iterator - makes doing shuffles of data easier\n",
    "\n",
    "all_docs2 = []\n",
    "sentences2 = LabeledLineSentence(questions_folder_name2, rows=num_question_pairs)\n",
    "for sentence in sentences2:\n",
    "    all_docs2.append(sentence)\n",
    "\n",
    "print('%d question pairs to train (%d documents total)' % (num_question_pairs, len(all_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80340 document pairs to classify\n",
      "Document pair names and labels contained in doc_names_and_duplicate_class\n"
     ]
    }
   ],
   "source": [
    "# make list of tuples (document1, document2, is_dup) for all num_question_pairs\n",
    "# the document names come from naming scheme used in LabeledLineSentence class \n",
    "\n",
    "questions_file_names = [os.path.basename(filename) for filename in os.listdir(questions_folder_name)]\n",
    "doc_names_and_duplicate_class = []\n",
    "for i, line in enumerate(open(dup_file_name)):\n",
    "    if i >= num_question_pairs:\n",
    "        break\n",
    "    doc_tup = (questions_file_names[0] + \"_\" + str(i), questions_file_names[1] + \"_\" + str(i), int(line.strip(\"\\n\")))\n",
    "    doc_names_and_duplicate_class.append(doc_tup)\n",
    "\n",
    "print (len(doc_names_and_duplicate_class), \"document pairs to classify\")\n",
    "print (\"Document pair names and labels contained in doc_names_and_duplicate_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20084 document pairs to classify\n",
      "Document pair names and labels contained in doc_names_and_duplicate_class2\n"
     ]
    }
   ],
   "source": [
    "# make list of tuples (document1, document2, is_dup) for all num_question_pairs\n",
    "# the document names come from naming scheme used in LabeledLineSentence class \n",
    "\n",
    "questions_file_names2 = [os.path.basename(filename) for filename in os.listdir(questions_folder_name2)]\n",
    "doc_names_and_duplicate_class2 = []\n",
    "for i, line in enumerate(open(dup_file_name2)):\n",
    "    if i >= num_question_pairs:\n",
    "        break\n",
    "    doc_tup = (questions_file_names2[0] + \"_\" + str(i), questions_file_names2[1] + \"_\" + str(i), int(line.strip(\"\\n\")))\n",
    "    doc_names_and_duplicate_class2.append(doc_tup)\n",
    "\n",
    "print (len(doc_names_and_duplicate_class2), \"document pairs to classify\")\n",
    "print (\"Document pair names and labels contained in doc_names_and_duplicate_class2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce logs during training\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "rootLogger = logging.getLogger()\n",
    "rootLogger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set model parameters parameters\n",
    "\n",
    "parameters_dict = {\n",
    "\n",
    "'documents' : all_docs,\n",
    "'dm' : 0, # use bag-of-words (dbow) model; 1 uses embedding (dmpv) model\n",
    "'size' : 200, # size of word/doc vectors\n",
    "'window' : 15, # # max distance between word and neighbor word for word embeddings\n",
    "'alpha' : .025, # learning rate - use rate in paper\n",
    "'min_alpha' : 0.0001, # rate from paper\n",
    "'min_count' : 5, # ignore words with count less than this\n",
    "'sample' : 1e-5, # how to configure downsampling for high frequency words\n",
    "'workers' : cores, # number of cores to use\n",
    "'hs' : 0, # use negative sampling\n",
    "'negative' : 5, # used in negative sampling\n",
    "'dbow_words' : 1, # trains word vectors in addition to document vectors in dbow model\n",
    "'iter' : 3 # recommended number of epochs is ~20 for dbow model on question comparison   \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of parameters to use in model\n",
    "from itertools import product\n",
    "\n",
    "dms = [0]\n",
    "sizes = [300]\n",
    "windows = [5]\n",
    "alphas = [0.025]\n",
    "min_alphas = [0.0001]\n",
    "min_counts = [1, 5]\n",
    "samples = [1e-5]\n",
    "workers_s = [cores]\n",
    "hs_s = [0]\n",
    "negatives = [5]\n",
    "dbow_words_s = [1]\n",
    "iters = [25]\n",
    "\n",
    "# create iterable of all combinations of parameters\n",
    "params_product = product(dms, sizes, windows, alphas, min_alphas, \n",
    "                        min_counts, samples, workers_s, hs_s, negatives, \n",
    "                        dbow_words_s, iters)\n",
    "parameters = [x for x in params_product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/gensim/models/doc2vec.py:362: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2018-04-16 22:14:25,877 : INFO : collecting all words and their counts\n",
      "2018-04-16 22:14:25,878 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-04-16 22:14:25,977 : INFO : PROGRESS: at example #10000, processed 138247 words (1403641/s), 5994 word types, 10000 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting first run of 2 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:14:26,077 : INFO : PROGRESS: at example #20000, processed 274419 words (1378975/s), 7051 word types, 20000 tags\n",
      "2018-04-16 22:14:26,189 : INFO : PROGRESS: at example #30000, processed 411567 words (1242516/s), 7634 word types, 30000 tags\n",
      "2018-04-16 22:14:26,289 : INFO : PROGRESS: at example #40000, processed 549845 words (1383608/s), 7918 word types, 40000 tags\n",
      "2018-04-16 22:14:26,389 : INFO : PROGRESS: at example #50000, processed 686582 words (1385579/s), 8085 word types, 50000 tags\n",
      "2018-04-16 22:14:26,476 : INFO : PROGRESS: at example #60000, processed 824684 words (1602945/s), 8190 word types, 60000 tags\n",
      "2018-04-16 22:14:26,612 : INFO : PROGRESS: at example #70000, processed 961911 words (1018083/s), 8283 word types, 70000 tags\n",
      "2018-04-16 22:14:26,766 : INFO : PROGRESS: at example #80000, processed 1098018 words (892439/s), 8342 word types, 80000 tags\n",
      "2018-04-16 22:14:27,282 : INFO : PROGRESS: at example #90000, processed 1234905 words (265933/s), 8404 word types, 90000 tags\n",
      "2018-04-16 22:14:27,377 : INFO : PROGRESS: at example #100000, processed 1369538 words (1450093/s), 8439 word types, 100000 tags\n",
      "2018-04-16 22:14:27,483 : INFO : PROGRESS: at example #110000, processed 1504169 words (1276817/s), 8451 word types, 110000 tags\n",
      "2018-04-16 22:14:27,626 : INFO : PROGRESS: at example #120000, processed 1640680 words (962615/s), 8452 word types, 120000 tags\n",
      "2018-04-16 22:14:27,733 : INFO : PROGRESS: at example #130000, processed 1777013 words (1279088/s), 8453 word types, 130000 tags\n",
      "2018-04-16 22:14:27,835 : INFO : PROGRESS: at example #140000, processed 1913252 words (1356903/s), 8455 word types, 140000 tags\n",
      "2018-04-16 22:14:27,951 : INFO : PROGRESS: at example #150000, processed 2050305 words (1201770/s), 8455 word types, 150000 tags\n",
      "2018-04-16 22:14:28,052 : INFO : PROGRESS: at example #160000, processed 2184382 words (1343415/s), 8456 word types, 160000 tags\n",
      "2018-04-16 22:14:28,061 : INFO : collected 8456 word types and 160680 unique tags from a corpus of 160680 examples and 2193663 words\n",
      "2018-04-16 22:14:28,062 : INFO : Loading a fresh vocabulary\n",
      "2018-04-16 22:14:28,103 : INFO : min_count=1 retains 8456 unique words (100% of original 8456, drops 0)\n",
      "2018-04-16 22:14:28,104 : INFO : min_count=1 leaves 2193663 word corpus (100% of original 2193663, drops 0)\n",
      "2018-04-16 22:14:28,137 : INFO : deleting the raw counts dictionary of 8456 items\n",
      "2018-04-16 22:14:28,138 : INFO : sample=1e-05 downsamples 2685 most-common words\n",
      "2018-04-16 22:14:28,139 : INFO : downsampling leaves estimated 403111 word corpus (18.4% of prior 2193663)\n",
      "2018-04-16 22:14:28,189 : INFO : estimated required memory for 8456 words and 300 dimensions: 249474400 bytes\n",
      "2018-04-16 22:14:28,190 : INFO : resetting layer weights\n",
      "2018-04-16 22:14:31,078 : INFO : training model with 4 workers on 8456 vocabulary and 300 features, using sg=1 hs=0 sample=1e-05 negative=5 window=5\n",
      "2018-04-16 22:14:32,106 : INFO : EPOCH 1 - PROGRESS: at 9.94% examples, 55721 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:14:33,202 : INFO : EPOCH 1 - PROGRESS: at 22.66% examples, 61204 words/s, in_qsize 7, out_qsize 1\n",
      "2018-04-16 22:14:34,241 : INFO : EPOCH 1 - PROGRESS: at 34.84% examples, 63246 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:35,259 : INFO : EPOCH 1 - PROGRESS: at 47.57% examples, 65287 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:36,272 : INFO : EPOCH 1 - PROGRESS: at 62.67% examples, 68752 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:37,310 : INFO : EPOCH 1 - PROGRESS: at 77.80% examples, 70779 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:38,329 : INFO : EPOCH 1 - PROGRESS: at 92.81% examples, 72380 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:38,732 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:14:38,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:14:38,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:14:38,776 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:14:38,777 : INFO : EPOCH - 1 : training on 2193663 raw words (563761 effective words) took 7.7s, 73350 effective words/s\n",
      "2018-04-16 22:14:39,799 : INFO : EPOCH 2 - PROGRESS: at 13.61% examples, 76869 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:40,807 : INFO : EPOCH 2 - PROGRESS: at 28.09% examples, 79611 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:41,840 : INFO : EPOCH 2 - PROGRESS: at 43.90% examples, 82312 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:42,871 : INFO : EPOCH 2 - PROGRESS: at 58.98% examples, 82188 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:43,901 : INFO : EPOCH 2 - PROGRESS: at 73.70% examples, 81497 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:44,949 : INFO : EPOCH 2 - PROGRESS: at 88.74% examples, 81223 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:45,622 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:14:45,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:14:45,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:14:45,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:14:45,662 : INFO : EPOCH - 2 : training on 2193663 raw words (562513 effective words) took 6.9s, 81922 effective words/s\n",
      "2018-04-16 22:14:46,685 : INFO : EPOCH 3 - PROGRESS: at 13.15% examples, 73977 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:14:47,700 : INFO : EPOCH 3 - PROGRESS: at 28.09% examples, 79123 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:14:48,717 : INFO : EPOCH 3 - PROGRESS: at 42.98% examples, 80716 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:14:49,742 : INFO : EPOCH 3 - PROGRESS: at 55.75% examples, 78035 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:50,771 : INFO : EPOCH 3 - PROGRESS: at 67.30% examples, 74831 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:51,829 : INFO : EPOCH 3 - PROGRESS: at 78.25% examples, 71880 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:52,855 : INFO : EPOCH 3 - PROGRESS: at 89.19% examples, 70080 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:53,630 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:14:53,665 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:14:53,673 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:14:53,684 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:14:53,685 : INFO : EPOCH - 3 : training on 2193663 raw words (563574 effective words) took 8.0s, 70315 effective words/s\n",
      "2018-04-16 22:14:54,748 : INFO : EPOCH 4 - PROGRESS: at 11.31% examples, 61762 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:55,758 : INFO : EPOCH 4 - PROGRESS: at 22.21% examples, 61647 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:14:56,786 : INFO : EPOCH 4 - PROGRESS: at 33.94% examples, 62919 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:14:57,827 : INFO : EPOCH 4 - PROGRESS: at 44.36% examples, 61533 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:14:58,872 : INFO : EPOCH 4 - PROGRESS: at 58.03% examples, 64002 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-16 22:14:59,891 : INFO : EPOCH 4 - PROGRESS: at 71.87% examples, 65836 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:00,910 : INFO : EPOCH 4 - PROGRESS: at 83.26% examples, 65342 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:01,949 : INFO : EPOCH 4 - PROGRESS: at 97.46% examples, 66680 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 22:15:02,045 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:02,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:02,090 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:15:02,092 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:02,093 : INFO : EPOCH - 4 : training on 2193663 raw words (563926 effective words) took 8.4s, 67217 effective words/s\n",
      "2018-04-16 22:15:03,135 : INFO : EPOCH 5 - PROGRESS: at 13.59% examples, 76066 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:04,148 : INFO : EPOCH 5 - PROGRESS: at 28.55% examples, 80271 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:15:05,158 : INFO : EPOCH 5 - PROGRESS: at 42.53% examples, 79996 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:06,203 : INFO : EPOCH 5 - PROGRESS: at 57.12% examples, 79634 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:07,230 : INFO : EPOCH 5 - PROGRESS: at 72.33% examples, 80134 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:08,257 : INFO : EPOCH 5 - PROGRESS: at 87.82% examples, 80824 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:08,999 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:09,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:09,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:15:09,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:09,048 : INFO : EPOCH - 5 : training on 2193663 raw words (564549 effective words) took 6.9s, 81379 effective words/s\n",
      "2018-04-16 22:15:10,059 : INFO : EPOCH 6 - PROGRESS: at 14.51% examples, 82627 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:11,061 : INFO : EPOCH 6 - PROGRESS: at 28.53% examples, 81300 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:12,062 : INFO : EPOCH 6 - PROGRESS: at 43.44% examples, 82612 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:13,076 : INFO : EPOCH 6 - PROGRESS: at 57.12% examples, 80904 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:14,126 : INFO : EPOCH 6 - PROGRESS: at 70.06% examples, 78219 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:15,171 : INFO : EPOCH 6 - PROGRESS: at 80.98% examples, 74818 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:16,194 : INFO : EPOCH 6 - PROGRESS: at 91.01% examples, 71942 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:17,023 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:17,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:17,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:15:17,058 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:17,059 : INFO : EPOCH - 6 : training on 2193663 raw words (563443 effective words) took 8.0s, 70402 effective words/s\n",
      "2018-04-16 22:15:18,132 : INFO : EPOCH 7 - PROGRESS: at 9.04% examples, 48949 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:19,207 : INFO : EPOCH 7 - PROGRESS: at 18.58% examples, 49721 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:20,231 : INFO : EPOCH 7 - PROGRESS: at 27.17% examples, 49177 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:21,252 : INFO : EPOCH 7 - PROGRESS: at 38.89% examples, 53247 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:22,360 : INFO : EPOCH 7 - PROGRESS: at 50.75% examples, 54860 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:23,372 : INFO : EPOCH 7 - PROGRESS: at 64.53% examples, 58222 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:24,404 : INFO : EPOCH 7 - PROGRESS: at 78.26% examples, 60452 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:25,415 : INFO : EPOCH 7 - PROGRESS: at 93.73% examples, 63457 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:25,785 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:25,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:25,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:15:25,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:25,809 : INFO : EPOCH - 7 : training on 2193663 raw words (563941 effective words) took 8.7s, 64581 effective words/s\n",
      "2018-04-16 22:15:26,913 : INFO : EPOCH 8 - PROGRESS: at 14.94% examples, 78854 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:27,919 : INFO : EPOCH 8 - PROGRESS: at 30.34% examples, 83090 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:28,929 : INFO : EPOCH 8 - PROGRESS: at 45.74% examples, 84396 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:29,939 : INFO : EPOCH 8 - PROGRESS: at 60.35% examples, 83515 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:31,003 : INFO : EPOCH 8 - PROGRESS: at 75.49% examples, 82599 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:32,030 : INFO : EPOCH 8 - PROGRESS: at 91.46% examples, 83285 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:32,545 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:32,569 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:32,585 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:15:32,592 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:32,593 : INFO : EPOCH - 8 : training on 2193663 raw words (564158 effective words) took 6.8s, 83386 effective words/s\n",
      "2018-04-16 22:15:33,603 : INFO : EPOCH 9 - PROGRESS: at 13.61% examples, 77715 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:34,612 : INFO : EPOCH 9 - PROGRESS: at 27.17% examples, 77318 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:35,633 : INFO : EPOCH 9 - PROGRESS: at 40.71% examples, 76827 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:36,673 : INFO : EPOCH 9 - PROGRESS: at 54.83% examples, 76843 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:37,690 : INFO : EPOCH 9 - PROGRESS: at 68.67% examples, 76531 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:38,745 : INFO : EPOCH 9 - PROGRESS: at 83.26% examples, 76637 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:39,750 : INFO : EPOCH 9 - PROGRESS: at 97.93% examples, 77267 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 22:15:39,764 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:39,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:39,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:15:39,823 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:39,824 : INFO : EPOCH - 9 : training on 2193663 raw words (563849 effective words) took 7.2s, 78085 effective words/s\n",
      "2018-04-16 22:15:40,839 : INFO : EPOCH 10 - PROGRESS: at 13.15% examples, 74167 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:41,840 : INFO : EPOCH 10 - PROGRESS: at 28.09% examples, 79711 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:42,845 : INFO : EPOCH 10 - PROGRESS: at 42.53% examples, 80596 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:43,873 : INFO : EPOCH 10 - PROGRESS: at 57.58% examples, 81178 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:44,933 : INFO : EPOCH 10 - PROGRESS: at 72.79% examples, 80805 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:45,958 : INFO : EPOCH 10 - PROGRESS: at 88.74% examples, 81834 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:46,705 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:46,711 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:46,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:15:46,725 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:46,726 : INFO : EPOCH - 10 : training on 2193663 raw words (563685 effective words) took 6.9s, 81764 effective words/s\n",
      "2018-04-16 22:15:47,736 : INFO : EPOCH 11 - PROGRESS: at 13.15% examples, 75223 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:48,756 : INFO : EPOCH 11 - PROGRESS: at 28.09% examples, 79649 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:49,831 : INFO : EPOCH 11 - PROGRESS: at 43.90% examples, 81216 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:50,841 : INFO : EPOCH 11 - PROGRESS: at 58.98% examples, 81855 words/s, in_qsize 8, out_qsize 1\n",
      "2018-04-16 22:15:51,852 : INFO : EPOCH 11 - PROGRESS: at 74.60% examples, 82505 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:52,860 : INFO : EPOCH 11 - PROGRESS: at 88.74% examples, 81784 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:53,553 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:15:53,554 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:15:53,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:15:53,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:15:53,567 : INFO : EPOCH - 11 : training on 2193663 raw words (563563 effective words) took 6.8s, 82473 effective words/s\n",
      "2018-04-16 22:15:54,589 : INFO : EPOCH 12 - PROGRESS: at 13.15% examples, 74051 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:15:55,599 : INFO : EPOCH 12 - PROGRESS: at 28.53% examples, 80719 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:56,608 : INFO : EPOCH 12 - PROGRESS: at 43.44% examples, 81976 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:57,624 : INFO : EPOCH 12 - PROGRESS: at 58.50% examples, 82372 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:58,666 : INFO : EPOCH 12 - PROGRESS: at 74.14% examples, 82484 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:15:59,679 : INFO : EPOCH 12 - PROGRESS: at 88.74% examples, 82123 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:00,335 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:00,339 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:00,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:00,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:00,371 : INFO : EPOCH - 12 : training on 2193663 raw words (563601 effective words) took 6.8s, 82957 effective words/s\n",
      "2018-04-16 22:16:01,383 : INFO : EPOCH 13 - PROGRESS: at 14.51% examples, 82380 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:02,452 : INFO : EPOCH 13 - PROGRESS: at 29.44% examples, 81220 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:03,453 : INFO : EPOCH 13 - PROGRESS: at 44.83% examples, 83304 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-16 22:16:04,456 : INFO : EPOCH 13 - PROGRESS: at 59.44% examples, 82860 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:05,474 : INFO : EPOCH 13 - PROGRESS: at 74.60% examples, 82828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:06,503 : INFO : EPOCH 13 - PROGRESS: at 89.63% examples, 82628 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:07,097 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:07,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:07,119 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:07,134 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:07,135 : INFO : EPOCH - 13 : training on 2193663 raw words (563369 effective words) took 6.8s, 83397 effective words/s\n",
      "2018-04-16 22:16:08,149 : INFO : EPOCH 14 - PROGRESS: at 13.61% examples, 77388 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:09,153 : INFO : EPOCH 14 - PROGRESS: at 28.55% examples, 81226 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:10,201 : INFO : EPOCH 14 - PROGRESS: at 43.90% examples, 82133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:11,224 : INFO : EPOCH 14 - PROGRESS: at 56.66% examples, 79190 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:12,233 : INFO : EPOCH 14 - PROGRESS: at 68.67% examples, 76526 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:13,303 : INFO : EPOCH 14 - PROGRESS: at 81.87% examples, 75170 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:14,313 : INFO : EPOCH 14 - PROGRESS: at 94.68% examples, 74477 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:14,692 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:14,732 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:14,745 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:14,748 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:14,749 : INFO : EPOCH - 14 : training on 2193663 raw words (563318 effective words) took 7.6s, 74082 effective words/s\n",
      "2018-04-16 22:16:15,787 : INFO : EPOCH 15 - PROGRESS: at 13.15% examples, 72896 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:16,788 : INFO : EPOCH 15 - PROGRESS: at 28.55% examples, 80479 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:17,848 : INFO : EPOCH 15 - PROGRESS: at 42.07% examples, 77902 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:18,853 : INFO : EPOCH 15 - PROGRESS: at 55.28% examples, 77085 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:19,887 : INFO : EPOCH 15 - PROGRESS: at 69.13% examples, 76440 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:20,934 : INFO : EPOCH 15 - PROGRESS: at 80.08% examples, 73342 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:21,958 : INFO : EPOCH 15 - PROGRESS: at 92.34% examples, 72403 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:22,496 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:22,512 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:22,531 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:22,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:22,539 : INFO : EPOCH - 15 : training on 2193663 raw words (563784 effective words) took 7.8s, 72451 effective words/s\n",
      "2018-04-16 22:16:23,588 : INFO : EPOCH 16 - PROGRESS: at 10.85% examples, 59526 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:24,598 : INFO : EPOCH 16 - PROGRESS: at 22.21% examples, 61763 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:25,608 : INFO : EPOCH 16 - PROGRESS: at 35.29% examples, 65952 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:26,619 : INFO : EPOCH 16 - PROGRESS: at 50.28% examples, 70635 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:27,651 : INFO : EPOCH 16 - PROGRESS: at 65.44% examples, 72838 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:28,683 : INFO : EPOCH 16 - PROGRESS: at 80.53% examples, 74210 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:29,713 : INFO : EPOCH 16 - PROGRESS: at 94.68% examples, 74492 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:30,087 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:30,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:30,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:30,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:30,122 : INFO : EPOCH - 16 : training on 2193663 raw words (563369 effective words) took 7.6s, 74385 effective words/s\n",
      "2018-04-16 22:16:31,144 : INFO : EPOCH 17 - PROGRESS: at 11.78% examples, 66540 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:32,164 : INFO : EPOCH 17 - PROGRESS: at 22.21% examples, 62569 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:33,197 : INFO : EPOCH 17 - PROGRESS: at 36.64% examples, 68535 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:34,198 : INFO : EPOCH 17 - PROGRESS: at 50.73% examples, 71419 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:35,211 : INFO : EPOCH 17 - PROGRESS: at 62.21% examples, 69669 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:36,233 : INFO : EPOCH 17 - PROGRESS: at 72.33% examples, 67184 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:37,258 : INFO : EPOCH 17 - PROGRESS: at 82.80% examples, 65741 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:38,346 : INFO : EPOCH 17 - PROGRESS: at 95.61% examples, 65700 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:38,538 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:38,562 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:38,586 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:38,592 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:38,593 : INFO : EPOCH - 17 : training on 2193663 raw words (563778 effective words) took 8.5s, 66680 effective words/s\n",
      "2018-04-16 22:16:39,627 : INFO : EPOCH 18 - PROGRESS: at 12.24% examples, 67975 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:40,632 : INFO : EPOCH 18 - PROGRESS: at 25.32% examples, 71343 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:41,655 : INFO : EPOCH 18 - PROGRESS: at 37.10% examples, 69401 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:16:42,669 : INFO : EPOCH 18 - PROGRESS: at 48.03% examples, 67444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:43,743 : INFO : EPOCH 18 - PROGRESS: at 59.44% examples, 65741 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:44,780 : INFO : EPOCH 18 - PROGRESS: at 71.42% examples, 65413 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:45,787 : INFO : EPOCH 18 - PROGRESS: at 82.33% examples, 64760 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:46,839 : INFO : EPOCH 18 - PROGRESS: at 92.82% examples, 63575 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:47,365 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:47,379 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:47,395 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:47,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:47,402 : INFO : EPOCH - 18 : training on 2193663 raw words (563535 effective words) took 8.8s, 64033 effective words/s\n",
      "2018-04-16 22:16:48,453 : INFO : EPOCH 19 - PROGRESS: at 9.48% examples, 52666 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:49,499 : INFO : EPOCH 19 - PROGRESS: at 20.84% examples, 57333 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:50,511 : INFO : EPOCH 19 - PROGRESS: at 31.70% examples, 58706 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:51,522 : INFO : EPOCH 19 - PROGRESS: at 42.52% examples, 59335 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:52,559 : INFO : EPOCH 19 - PROGRESS: at 53.02% examples, 58898 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:16:53,581 : INFO : EPOCH 19 - PROGRESS: at 63.60% examples, 58635 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:54,633 : INFO : EPOCH 19 - PROGRESS: at 75.51% examples, 59260 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:55,700 : INFO : EPOCH 19 - PROGRESS: at 87.82% examples, 59906 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:56,605 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:16:56,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:16:56,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:16:56,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:16:56,664 : INFO : EPOCH - 19 : training on 2193663 raw words (563652 effective words) took 9.2s, 60973 effective words/s\n",
      "2018-04-16 22:16:57,684 : INFO : EPOCH 20 - PROGRESS: at 11.77% examples, 66588 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:58,792 : INFO : EPOCH 20 - PROGRESS: at 23.99% examples, 64880 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:16:59,843 : INFO : EPOCH 20 - PROGRESS: at 35.30% examples, 63851 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:00,863 : INFO : EPOCH 20 - PROGRESS: at 47.57% examples, 65044 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:01,893 : INFO : EPOCH 20 - PROGRESS: at 63.13% examples, 68803 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:02,932 : INFO : EPOCH 20 - PROGRESS: at 78.25% examples, 70820 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:03,992 : INFO : EPOCH 20 - PROGRESS: at 94.20% examples, 72666 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:04,264 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:17:04,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:17:04,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:17:04,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:17:04,316 : INFO : EPOCH - 20 : training on 2193663 raw words (563953 effective words) took 7.6s, 73795 effective words/s\n",
      "2018-04-16 22:17:05,411 : INFO : EPOCH 21 - PROGRESS: at 14.94% examples, 78684 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:06,418 : INFO : EPOCH 21 - PROGRESS: at 30.80% examples, 84165 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:07,478 : INFO : EPOCH 21 - PROGRESS: at 45.74% examples, 82999 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:08,491 : INFO : EPOCH 21 - PROGRESS: at 61.28% examples, 83658 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:09,503 : INFO : EPOCH 21 - PROGRESS: at 76.42% examples, 83535 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:10,520 : INFO : EPOCH 21 - PROGRESS: at 91.02% examples, 82959 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:11,047 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:17:11,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:17:11,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:17:11,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:17:11,090 : INFO : EPOCH - 21 : training on 2193663 raw words (563482 effective words) took 6.8s, 83328 effective words/s\n",
      "2018-04-16 22:17:12,110 : INFO : EPOCH 22 - PROGRESS: at 13.61% examples, 76764 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-16 22:17:13,169 : INFO : EPOCH 22 - PROGRESS: at 29.44% examples, 81460 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:14,216 : INFO : EPOCH 22 - PROGRESS: at 44.36% examples, 81488 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:15,241 : INFO : EPOCH 22 - PROGRESS: at 58.50% examples, 80494 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:16,293 : INFO : EPOCH 22 - PROGRESS: at 74.14% examples, 80810 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:17,320 : INFO : EPOCH 22 - PROGRESS: at 88.74% examples, 80530 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:17,970 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:17:17,989 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:17:18,011 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:17:18,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:17:18,023 : INFO : EPOCH - 22 : training on 2193663 raw words (563391 effective words) took 6.9s, 81382 effective words/s\n",
      "2018-04-16 22:17:19,054 : INFO : EPOCH 23 - PROGRESS: at 13.15% examples, 73355 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:20,057 : INFO : EPOCH 23 - PROGRESS: at 28.55% examples, 80783 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:21,062 : INFO : EPOCH 23 - PROGRESS: at 42.98% examples, 81304 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:22,087 : INFO : EPOCH 23 - PROGRESS: at 58.05% examples, 81717 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:23,093 : INFO : EPOCH 23 - PROGRESS: at 69.13% examples, 77571 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:24,095 : INFO : EPOCH 23 - PROGRESS: at 80.98% examples, 75651 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:25,149 : INFO : EPOCH 23 - PROGRESS: at 93.73% examples, 74425 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:25,574 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:17:25,605 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:17:25,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:17:25,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:17:25,654 : INFO : EPOCH - 23 : training on 2193663 raw words (564467 effective words) took 7.6s, 74065 effective words/s\n",
      "2018-04-16 22:17:26,697 : INFO : EPOCH 24 - PROGRESS: at 10.40% examples, 57743 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:27,704 : INFO : EPOCH 24 - PROGRESS: at 22.21% examples, 62392 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:28,714 : INFO : EPOCH 24 - PROGRESS: at 33.50% examples, 62927 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:29,736 : INFO : EPOCH 24 - PROGRESS: at 44.84% examples, 63076 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:30,739 : INFO : EPOCH 24 - PROGRESS: at 59.89% examples, 67236 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:31,766 : INFO : EPOCH 24 - PROGRESS: at 74.60% examples, 69282 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:32,793 : INFO : EPOCH 24 - PROGRESS: at 90.56% examples, 71768 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:17:33,337 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:17:33,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:17:33,381 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:17:33,383 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:17:33,384 : INFO : EPOCH - 24 : training on 2193663 raw words (563601 effective words) took 7.7s, 73046 effective words/s\n",
      "2018-04-16 22:17:34,407 : INFO : EPOCH 25 - PROGRESS: at 13.61% examples, 77356 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:35,424 : INFO : EPOCH 25 - PROGRESS: at 29.44% examples, 83371 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:36,453 : INFO : EPOCH 25 - PROGRESS: at 44.36% examples, 83274 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:37,470 : INFO : EPOCH 25 - PROGRESS: at 59.89% examples, 83912 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:38,511 : INFO : EPOCH 25 - PROGRESS: at 75.49% examples, 83759 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:39,532 : INFO : EPOCH 25 - PROGRESS: at 91.02% examples, 83919 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:40,081 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:17:40,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:17:40,104 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:17:40,116 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:17:40,117 : INFO : EPOCH - 25 : training on 2193663 raw words (564326 effective words) took 6.7s, 84048 effective words/s\n",
      "2018-04-16 22:17:40,118 : INFO : training on a 54841575 raw words (14092588 effective words) took 189.0s, 74551 effective words/s\n",
      "2018-04-16 22:17:42,114 : INFO : collecting all words and their counts\n",
      "2018-04-16 22:17:42,115 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-04-16 22:17:42,209 : INFO : PROGRESS: at example #10000, processed 138247 words (1500593/s), 5994 word types, 10000 tags\n",
      "2018-04-16 22:17:42,299 : INFO : PROGRESS: at example #20000, processed 274419 words (1530946/s), 7051 word types, 20000 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed run number 1 of 2 runs total\n",
      "AUC score: 0.9284\n",
      "Training for this run took 3.3 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:17:42,395 : INFO : PROGRESS: at example #30000, processed 411567 words (1441656/s), 7634 word types, 30000 tags\n",
      "2018-04-16 22:17:42,514 : INFO : PROGRESS: at example #40000, processed 549845 words (1170815/s), 7918 word types, 40000 tags\n",
      "2018-04-16 22:17:42,642 : INFO : PROGRESS: at example #50000, processed 686582 words (1091546/s), 8085 word types, 50000 tags\n",
      "2018-04-16 22:17:42,752 : INFO : PROGRESS: at example #60000, processed 824684 words (1260255/s), 8190 word types, 60000 tags\n",
      "2018-04-16 22:17:42,846 : INFO : PROGRESS: at example #70000, processed 961911 words (1487371/s), 8283 word types, 70000 tags\n",
      "2018-04-16 22:17:42,929 : INFO : PROGRESS: at example #80000, processed 1098018 words (1650884/s), 8342 word types, 80000 tags\n",
      "2018-04-16 22:17:43,017 : INFO : PROGRESS: at example #90000, processed 1234905 words (1580886/s), 8404 word types, 90000 tags\n",
      "2018-04-16 22:17:43,118 : INFO : PROGRESS: at example #100000, processed 1369538 words (1354772/s), 8439 word types, 100000 tags\n",
      "2018-04-16 22:17:43,213 : INFO : PROGRESS: at example #110000, processed 1504169 words (1433514/s), 8451 word types, 110000 tags\n",
      "2018-04-16 22:17:43,315 : INFO : PROGRESS: at example #120000, processed 1640680 words (1362406/s), 8452 word types, 120000 tags\n",
      "2018-04-16 22:17:43,694 : INFO : PROGRESS: at example #130000, processed 1777013 words (360390/s), 8453 word types, 130000 tags\n",
      "2018-04-16 22:17:43,776 : INFO : PROGRESS: at example #140000, processed 1913252 words (1696821/s), 8455 word types, 140000 tags\n",
      "2018-04-16 22:17:43,872 : INFO : PROGRESS: at example #150000, processed 2050305 words (1439335/s), 8455 word types, 150000 tags\n",
      "2018-04-16 22:17:43,975 : INFO : PROGRESS: at example #160000, processed 2184382 words (1319431/s), 8456 word types, 160000 tags\n",
      "2018-04-16 22:17:43,984 : INFO : collected 8456 word types and 160680 unique tags from a corpus of 160680 examples and 2193663 words\n",
      "2018-04-16 22:17:43,986 : INFO : Loading a fresh vocabulary\n",
      "2018-04-16 22:17:44,019 : INFO : min_count=5 retains 7876 unique words (93% of original 8456, drops 580)\n",
      "2018-04-16 22:17:44,019 : INFO : min_count=5 leaves 2192099 word corpus (99% of original 2193663, drops 1564)\n",
      "2018-04-16 22:17:44,063 : INFO : deleting the raw counts dictionary of 8456 items\n",
      "2018-04-16 22:17:44,065 : INFO : sample=1e-05 downsamples 2685 most-common words\n",
      "2018-04-16 22:17:44,066 : INFO : downsampling leaves estimated 401419 word corpus (18.3% of prior 2192099)\n",
      "2018-04-16 22:17:44,107 : INFO : estimated required memory for 7876 words and 300 dimensions: 247792400 bytes\n",
      "2018-04-16 22:17:44,108 : INFO : resetting layer weights\n",
      "2018-04-16 22:17:47,253 : INFO : training model with 4 workers on 7876 vocabulary and 300 features, using sg=1 hs=0 sample=1e-05 negative=5 window=5\n",
      "2018-04-16 22:17:48,326 : INFO : EPOCH 1 - PROGRESS: at 9.94% examples, 53059 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:49,351 : INFO : EPOCH 1 - PROGRESS: at 21.75% examples, 59177 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:50,366 : INFO : EPOCH 1 - PROGRESS: at 32.60% examples, 59865 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:51,441 : INFO : EPOCH 1 - PROGRESS: at 43.46% examples, 59242 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:52,446 : INFO : EPOCH 1 - PROGRESS: at 54.83% examples, 60101 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:53,482 : INFO : EPOCH 1 - PROGRESS: at 65.91% examples, 59924 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:54,491 : INFO : EPOCH 1 - PROGRESS: at 76.44% examples, 59614 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:55,593 : INFO : EPOCH 1 - PROGRESS: at 88.28% examples, 59682 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:56,493 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:17:56,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:17:56,536 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:17:56,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:17:56,544 : INFO : EPOCH - 1 : training on 2193663 raw words (562429 effective words) took 9.3s, 60586 effective words/s\n",
      "2018-04-16 22:17:57,571 : INFO : EPOCH 2 - PROGRESS: at 10.84% examples, 60558 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:17:58,612 : INFO : EPOCH 2 - PROGRESS: at 21.75% examples, 60244 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:17:59,672 : INFO : EPOCH 2 - PROGRESS: at 33.48% examples, 61310 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:00,673 : INFO : EPOCH 2 - PROGRESS: at 43.90% examples, 60808 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:01,685 : INFO : EPOCH 2 - PROGRESS: at 54.83% examples, 60764 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:02,724 : INFO : EPOCH 2 - PROGRESS: at 65.44% examples, 60005 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:03,758 : INFO : EPOCH 2 - PROGRESS: at 76.88% examples, 60204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:04,772 : INFO : EPOCH 2 - PROGRESS: at 86.89% examples, 59554 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:05,829 : INFO : EPOCH 2 - PROGRESS: at 98.37% examples, 59650 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-16 22:18:05,843 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:18:05,905 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:18:05,919 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:18:05,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:18:05,921 : INFO : EPOCH - 2 : training on 2193663 raw words (562127 effective words) took 9.4s, 60021 effective words/s\n",
      "2018-04-16 22:18:06,945 : INFO : EPOCH 3 - PROGRESS: at 11.31% examples, 63509 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:07,950 : INFO : EPOCH 3 - PROGRESS: at 26.24% examples, 74079 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:08,960 : INFO : EPOCH 3 - PROGRESS: at 41.18% examples, 77492 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:09,973 : INFO : EPOCH 3 - PROGRESS: at 56.20% examples, 79084 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:10,979 : INFO : EPOCH 3 - PROGRESS: at 70.96% examples, 79407 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:12,042 : INFO : EPOCH 3 - PROGRESS: at 86.92% examples, 80126 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:12,807 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:18:12,841 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:18:12,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:18:12,859 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:18:12,860 : INFO : EPOCH - 3 : training on 2193663 raw words (562584 effective words) took 6.9s, 81195 effective words/s\n",
      "2018-04-16 22:18:13,915 : INFO : EPOCH 4 - PROGRESS: at 13.61% examples, 74831 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:14,923 : INFO : EPOCH 4 - PROGRESS: at 28.55% examples, 79481 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:15,981 : INFO : EPOCH 4 - PROGRESS: at 42.07% examples, 77180 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:16,983 : INFO : EPOCH 4 - PROGRESS: at 56.66% examples, 78385 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:17,987 : INFO : EPOCH 4 - PROGRESS: at 69.60% examples, 76939 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:18,997 : INFO : EPOCH 4 - PROGRESS: at 83.73% examples, 77086 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:20,000 : INFO : EPOCH 4 - PROGRESS: at 98.39% examples, 77660 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-16 22:18:20,030 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:18:20,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:18:20,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:18:20,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:18:20,062 : INFO : EPOCH - 4 : training on 2193663 raw words (561741 effective words) took 7.2s, 78234 effective words/s\n",
      "2018-04-16 22:18:21,117 : INFO : EPOCH 5 - PROGRESS: at 13.15% examples, 71413 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:18:22,118 : INFO : EPOCH 5 - PROGRESS: at 28.53% examples, 79400 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:23,126 : INFO : EPOCH 5 - PROGRESS: at 42.53% examples, 79298 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:24,134 : INFO : EPOCH 5 - PROGRESS: at 58.05% examples, 81048 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:25,192 : INFO : EPOCH 5 - PROGRESS: at 73.25% examples, 80675 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:26,194 : INFO : EPOCH 5 - PROGRESS: at 88.28% examples, 81180 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:26,906 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:18:26,930 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:18:26,937 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:18:26,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:18:26,950 : INFO : EPOCH - 5 : training on 2193663 raw words (562064 effective words) took 6.9s, 81708 effective words/s\n",
      "2018-04-16 22:18:28,053 : INFO : EPOCH 6 - PROGRESS: at 14.94% examples, 77751 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:29,067 : INFO : EPOCH 6 - PROGRESS: at 30.80% examples, 83215 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:30,132 : INFO : EPOCH 6 - PROGRESS: at 45.74% examples, 82171 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:31,138 : INFO : EPOCH 6 - PROGRESS: at 60.80% examples, 82433 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:32,169 : INFO : EPOCH 6 - PROGRESS: at 76.42% examples, 82676 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:33,182 : INFO : EPOCH 6 - PROGRESS: at 91.46% examples, 82658 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:33,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:18:33,717 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:18:33,729 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:18:33,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:18:33,736 : INFO : EPOCH - 6 : training on 2193663 raw words (561897 effective words) took 6.8s, 82901 effective words/s\n",
      "2018-04-16 22:18:34,804 : INFO : EPOCH 7 - PROGRESS: at 13.61% examples, 73244 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:35,852 : INFO : EPOCH 7 - PROGRESS: at 26.70% examples, 72214 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:36,867 : INFO : EPOCH 7 - PROGRESS: at 37.10% examples, 67734 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:37,885 : INFO : EPOCH 7 - PROGRESS: at 49.39% examples, 67917 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:38,908 : INFO : EPOCH 7 - PROGRESS: at 61.28% examples, 67199 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:39,938 : INFO : EPOCH 7 - PROGRESS: at 72.79% examples, 66252 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:40,941 : INFO : EPOCH 7 - PROGRESS: at 82.80% examples, 64810 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:41,991 : INFO : EPOCH 7 - PROGRESS: at 92.81% examples, 63297 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:42,593 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:18:42,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:18:42,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:18:42,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:18:42,628 : INFO : EPOCH - 7 : training on 2193663 raw words (561663 effective words) took 8.9s, 63276 effective words/s\n",
      "2018-04-16 22:18:43,674 : INFO : EPOCH 8 - PROGRESS: at 10.40% examples, 57105 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:44,688 : INFO : EPOCH 8 - PROGRESS: at 21.75% examples, 60313 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:45,720 : INFO : EPOCH 8 - PROGRESS: at 34.84% examples, 64458 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:46,726 : INFO : EPOCH 8 - PROGRESS: at 46.65% examples, 64993 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:47,729 : INFO : EPOCH 8 - PROGRESS: at 58.52% examples, 65210 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:48,820 : INFO : EPOCH 8 - PROGRESS: at 70.50% examples, 64401 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:18:49,834 : INFO : EPOCH 8 - PROGRESS: at 81.42% examples, 63789 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:50,891 : INFO : EPOCH 8 - PROGRESS: at 92.80% examples, 63303 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:51,412 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:18:51,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:18:51,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:18:51,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:18:51,444 : INFO : EPOCH - 8 : training on 2193663 raw words (562393 effective words) took 8.8s, 63860 effective words/s\n",
      "2018-04-16 22:18:52,481 : INFO : EPOCH 9 - PROGRESS: at 9.94% examples, 55133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:53,520 : INFO : EPOCH 9 - PROGRESS: at 20.84% examples, 57356 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:54,547 : INFO : EPOCH 9 - PROGRESS: at 31.69% examples, 58296 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:55,619 : INFO : EPOCH 9 - PROGRESS: at 43.44% examples, 59297 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:56,648 : INFO : EPOCH 9 - PROGRESS: at 55.30% examples, 60373 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:57,660 : INFO : EPOCH 9 - PROGRESS: at 66.37% examples, 60384 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:58,732 : INFO : EPOCH 9 - PROGRESS: at 76.88% examples, 59472 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:18:59,742 : INFO : EPOCH 9 - PROGRESS: at 88.74% examples, 60184 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:00,670 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:00,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:00,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:00,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:00,735 : INFO : EPOCH - 9 : training on 2193663 raw words (561295 effective words) took 9.3s, 60471 effective words/s\n",
      "2018-04-16 22:19:01,753 : INFO : EPOCH 10 - PROGRESS: at 10.84% examples, 61349 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:02,803 : INFO : EPOCH 10 - PROGRESS: at 21.75% examples, 60336 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:03,862 : INFO : EPOCH 10 - PROGRESS: at 33.95% examples, 62191 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:04,889 : INFO : EPOCH 10 - PROGRESS: at 45.74% examples, 63007 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:05,894 : INFO : EPOCH 10 - PROGRESS: at 56.20% examples, 62111 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:06,937 : INFO : EPOCH 10 - PROGRESS: at 66.82% examples, 61181 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:08,011 : INFO : EPOCH 10 - PROGRESS: at 78.71% examples, 61192 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:09,027 : INFO : EPOCH 10 - PROGRESS: at 89.65% examples, 61040 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:09,717 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:09,751 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:09,758 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:09,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:09,763 : INFO : EPOCH - 10 : training on 2193663 raw words (562995 effective words) took 9.0s, 62422 effective words/s\n",
      "2018-04-16 22:19:10,795 : INFO : EPOCH 11 - PROGRESS: at 10.40% examples, 57778 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:11,832 : INFO : EPOCH 11 - PROGRESS: at 22.66% examples, 62487 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:12,853 : INFO : EPOCH 11 - PROGRESS: at 34.84% examples, 64353 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:13,855 : INFO : EPOCH 11 - PROGRESS: at 46.19% examples, 64429 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:19:14,869 : INFO : EPOCH 11 - PROGRESS: at 59.44% examples, 66095 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:15,943 : INFO : EPOCH 11 - PROGRESS: at 70.96% examples, 64907 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:16,944 : INFO : EPOCH 11 - PROGRESS: at 84.63% examples, 66441 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:17,952 : INFO : EPOCH 11 - PROGRESS: at 96.53% examples, 66334 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:18,126 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:18,141 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:18,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:18,161 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:18,162 : INFO : EPOCH - 11 : training on 2193663 raw words (562046 effective words) took 8.4s, 66981 effective words/s\n",
      "2018-04-16 22:19:19,232 : INFO : EPOCH 12 - PROGRESS: at 13.15% examples, 70378 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:20,261 : INFO : EPOCH 12 - PROGRESS: at 23.55% examples, 64133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:21,278 : INFO : EPOCH 12 - PROGRESS: at 34.84% examples, 63839 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:22,279 : INFO : EPOCH 12 - PROGRESS: at 46.65% examples, 64626 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:23,290 : INFO : EPOCH 12 - PROGRESS: at 59.89% examples, 66290 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:24,296 : INFO : EPOCH 12 - PROGRESS: at 74.14% examples, 68284 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:25,346 : INFO : EPOCH 12 - PROGRESS: at 89.65% examples, 70336 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:26,034 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:26,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:26,074 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:26,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:26,083 : INFO : EPOCH - 12 : training on 2193663 raw words (562182 effective words) took 7.9s, 71051 effective words/s\n",
      "2018-04-16 22:19:27,093 : INFO : EPOCH 13 - PROGRESS: at 11.78% examples, 66741 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:28,178 : INFO : EPOCH 13 - PROGRESS: at 23.11% examples, 62988 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:29,188 : INFO : EPOCH 13 - PROGRESS: at 34.39% examples, 63238 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:30,222 : INFO : EPOCH 13 - PROGRESS: at 47.12% examples, 64869 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:31,223 : INFO : EPOCH 13 - PROGRESS: at 58.06% examples, 64139 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:32,309 : INFO : EPOCH 13 - PROGRESS: at 70.96% examples, 64374 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:33,331 : INFO : EPOCH 13 - PROGRESS: at 82.79% examples, 64389 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:34,333 : INFO : EPOCH 13 - PROGRESS: at 95.13% examples, 64862 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:34,711 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:34,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:34,733 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:34,744 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:34,744 : INFO : EPOCH - 13 : training on 2193663 raw words (561461 effective words) took 8.7s, 64894 effective words/s\n",
      "2018-04-16 22:19:35,772 : INFO : EPOCH 14 - PROGRESS: at 9.94% examples, 55644 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:36,773 : INFO : EPOCH 14 - PROGRESS: at 20.38% examples, 57416 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:37,808 : INFO : EPOCH 14 - PROGRESS: at 33.05% examples, 61707 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:38,846 : INFO : EPOCH 14 - PROGRESS: at 43.44% examples, 60539 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:39,857 : INFO : EPOCH 14 - PROGRESS: at 57.13% examples, 63624 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:40,867 : INFO : EPOCH 14 - PROGRESS: at 71.42% examples, 66060 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:41,870 : INFO : EPOCH 14 - PROGRESS: at 84.18% examples, 66720 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:42,876 : INFO : EPOCH 14 - PROGRESS: at 96.08% examples, 66563 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:43,097 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:43,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:43,123 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:43,132 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:43,133 : INFO : EPOCH - 14 : training on 2193663 raw words (562362 effective words) took 8.4s, 67110 effective words/s\n",
      "2018-04-16 22:19:44,169 : INFO : EPOCH 15 - PROGRESS: at 11.31% examples, 62645 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:45,207 : INFO : EPOCH 15 - PROGRESS: at 24.43% examples, 67454 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:46,215 : INFO : EPOCH 15 - PROGRESS: at 37.54% examples, 69784 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:47,257 : INFO : EPOCH 15 - PROGRESS: at 49.39% examples, 68426 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:48,257 : INFO : EPOCH 15 - PROGRESS: at 62.21% examples, 68945 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:49,258 : INFO : EPOCH 15 - PROGRESS: at 75.52% examples, 69714 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:50,260 : INFO : EPOCH 15 - PROGRESS: at 88.28% examples, 69845 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:19:51,308 : INFO : EPOCH 15 - PROGRESS: at 98.39% examples, 67747 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-16 22:19:51,314 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:51,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:51,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:51,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:51,352 : INFO : EPOCH - 15 : training on 2193663 raw words (562121 effective words) took 8.2s, 68477 effective words/s\n",
      "2018-04-16 22:19:52,428 : INFO : EPOCH 16 - PROGRESS: at 10.86% examples, 57909 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:53,495 : INFO : EPOCH 16 - PROGRESS: at 22.21% examples, 59230 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:54,581 : INFO : EPOCH 16 - PROGRESS: at 34.39% examples, 60847 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:55,598 : INFO : EPOCH 16 - PROGRESS: at 47.11% examples, 63392 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:56,630 : INFO : EPOCH 16 - PROGRESS: at 62.67% examples, 67425 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:57,631 : INFO : EPOCH 16 - PROGRESS: at 76.42% examples, 68838 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:58,634 : INFO : EPOCH 16 - PROGRESS: at 91.46% examples, 70806 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:19:59,147 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:19:59,155 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:19:59,176 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:19:59,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:19:59,180 : INFO : EPOCH - 16 : training on 2193663 raw words (562096 effective words) took 7.8s, 71910 effective words/s\n",
      "2018-04-16 22:20:00,208 : INFO : EPOCH 17 - PROGRESS: at 13.15% examples, 73146 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:01,231 : INFO : EPOCH 17 - PROGRESS: at 26.70% examples, 74256 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:02,290 : INFO : EPOCH 17 - PROGRESS: at 40.26% examples, 73796 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:03,347 : INFO : EPOCH 17 - PROGRESS: at 53.48% examples, 73055 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:20:04,353 : INFO : EPOCH 17 - PROGRESS: at 67.75% examples, 74064 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:05,363 : INFO : EPOCH 17 - PROGRESS: at 80.53% examples, 73422 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:06,369 : INFO : EPOCH 17 - PROGRESS: at 94.19% examples, 73725 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:06,804 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:20:06,821 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:20:06,832 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:20:06,839 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:20:06,840 : INFO : EPOCH - 17 : training on 2193663 raw words (561650 effective words) took 7.6s, 73423 effective words/s\n",
      "2018-04-16 22:20:07,855 : INFO : EPOCH 18 - PROGRESS: at 12.23% examples, 69702 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:08,873 : INFO : EPOCH 18 - PROGRESS: at 26.70% examples, 75184 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:09,881 : INFO : EPOCH 18 - PROGRESS: at 40.26% examples, 75670 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:10,885 : INFO : EPOCH 18 - PROGRESS: at 53.02% examples, 74729 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:11,969 : INFO : EPOCH 18 - PROGRESS: at 66.82% examples, 73807 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:12,975 : INFO : EPOCH 18 - PROGRESS: at 81.42% examples, 74937 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:14,057 : INFO : EPOCH 18 - PROGRESS: at 96.07% examples, 74996 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:14,208 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:20:14,218 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:20:14,233 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:20:14,248 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:20:14,249 : INFO : EPOCH - 18 : training on 2193663 raw words (562014 effective words) took 7.4s, 76004 effective words/s\n",
      "2018-04-16 22:20:15,299 : INFO : EPOCH 19 - PROGRESS: at 13.59% examples, 74554 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:16,401 : INFO : EPOCH 19 - PROGRESS: at 26.70% examples, 70882 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:17,409 : INFO : EPOCH 19 - PROGRESS: at 40.26% examples, 72711 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:18,440 : INFO : EPOCH 19 - PROGRESS: at 52.10% examples, 70716 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:19,455 : INFO : EPOCH 19 - PROGRESS: at 66.82% examples, 72574 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:20,481 : INFO : EPOCH 19 - PROGRESS: at 81.42% examples, 73634 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:21,522 : INFO : EPOCH 19 - PROGRESS: at 95.61% examples, 73909 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:21,752 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:20:21,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:20:21,786 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:20:21,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:20:21,808 : INFO : EPOCH - 19 : training on 2193663 raw words (560747 effective words) took 7.5s, 74340 effective words/s\n",
      "2018-04-16 22:20:22,869 : INFO : EPOCH 20 - PROGRESS: at 13.15% examples, 71000 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:23,880 : INFO : EPOCH 20 - PROGRESS: at 25.79% examples, 71256 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:24,982 : INFO : EPOCH 20 - PROGRESS: at 40.25% examples, 72423 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:26,004 : INFO : EPOCH 20 - PROGRESS: at 53.92% examples, 73225 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:27,026 : INFO : EPOCH 20 - PROGRESS: at 69.13% examples, 75016 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:28,037 : INFO : EPOCH 20 - PROGRESS: at 84.63% examples, 76719 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:29,092 : INFO : EPOCH 20 - PROGRESS: at 97.93% examples, 75745 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 22:20:29,170 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:20:29,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:20:29,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:20:29,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:20:29,209 : INFO : EPOCH - 20 : training on 2193663 raw words (562567 effective words) took 7.4s, 76105 effective words/s\n",
      "2018-04-16 22:20:30,242 : INFO : EPOCH 21 - PROGRESS: at 11.31% examples, 63452 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:31,252 : INFO : EPOCH 21 - PROGRESS: at 24.88% examples, 69974 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:32,254 : INFO : EPOCH 21 - PROGRESS: at 37.54% examples, 70703 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:33,322 : INFO : EPOCH 21 - PROGRESS: at 50.73% examples, 70523 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:34,324 : INFO : EPOCH 21 - PROGRESS: at 65.91% examples, 73120 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:35,328 : INFO : EPOCH 21 - PROGRESS: at 78.71% examples, 72721 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:36,343 : INFO : EPOCH 21 - PROGRESS: at 92.34% examples, 72982 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:36,756 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:20:36,778 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:20:36,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:20:36,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:20:36,801 : INFO : EPOCH - 21 : training on 2193663 raw words (561920 effective words) took 7.6s, 74170 effective words/s\n",
      "2018-04-16 22:20:37,824 : INFO : EPOCH 22 - PROGRESS: at 13.61% examples, 77032 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:38,838 : INFO : EPOCH 22 - PROGRESS: at 26.24% examples, 73953 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:39,840 : INFO : EPOCH 22 - PROGRESS: at 37.10% examples, 69880 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:40,890 : INFO : EPOCH 22 - PROGRESS: at 49.84% examples, 69573 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:41,935 : INFO : EPOCH 22 - PROGRESS: at 61.75% examples, 68273 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:42,971 : INFO : EPOCH 22 - PROGRESS: at 74.60% examples, 68317 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:43,986 : INFO : EPOCH 22 - PROGRESS: at 89.19% examples, 69998 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:44,609 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:20:44,612 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:20:44,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:20:44,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:20:44,633 : INFO : EPOCH - 22 : training on 2193663 raw words (561419 effective words) took 7.8s, 71872 effective words/s\n",
      "2018-04-16 22:20:45,654 : INFO : EPOCH 23 - PROGRESS: at 12.24% examples, 68444 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:46,695 : INFO : EPOCH 23 - PROGRESS: at 24.88% examples, 68959 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:47,726 : INFO : EPOCH 23 - PROGRESS: at 36.21% examples, 66915 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:48,801 : INFO : EPOCH 23 - PROGRESS: at 46.65% examples, 63910 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:49,808 : INFO : EPOCH 23 - PROGRESS: at 57.58% examples, 63350 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:20:50,816 : INFO : EPOCH 23 - PROGRESS: at 68.67% examples, 62885 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:51,841 : INFO : EPOCH 23 - PROGRESS: at 81.42% examples, 63784 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:52,949 : INFO : EPOCH 23 - PROGRESS: at 94.20% examples, 63816 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:20:53,283 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:20:53,310 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:20:53,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:20:53,345 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:20:53,346 : INFO : EPOCH - 23 : training on 2193663 raw words (562230 effective words) took 8.7s, 64599 effective words/s\n",
      "2018-04-16 22:20:54,369 : INFO : EPOCH 24 - PROGRESS: at 10.84% examples, 60607 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:55,371 : INFO : EPOCH 24 - PROGRESS: at 23.99% examples, 67458 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:56,393 : INFO : EPOCH 24 - PROGRESS: at 34.39% examples, 64273 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:57,412 : INFO : EPOCH 24 - PROGRESS: at 44.36% examples, 62115 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:58,439 : INFO : EPOCH 24 - PROGRESS: at 56.66% examples, 63183 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:20:59,472 : INFO : EPOCH 24 - PROGRESS: at 69.60% examples, 64190 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:21:00,476 : INFO : EPOCH 24 - PROGRESS: at 82.33% examples, 65131 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:21:01,476 : INFO : EPOCH 24 - PROGRESS: at 95.61% examples, 66146 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:21:01,742 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:21:01,764 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:21:01,775 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:21:01,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:21:01,779 : INFO : EPOCH - 24 : training on 2193663 raw words (561719 effective words) took 8.4s, 66673 effective words/s\n",
      "2018-04-16 22:21:02,805 : INFO : EPOCH 25 - PROGRESS: at 11.78% examples, 65920 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:21:03,832 : INFO : EPOCH 25 - PROGRESS: at 24.88% examples, 69375 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:21:04,864 : INFO : EPOCH 25 - PROGRESS: at 38.43% examples, 71214 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:21:05,874 : INFO : EPOCH 25 - PROGRESS: at 52.58% examples, 73217 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:21:06,923 : INFO : EPOCH 25 - PROGRESS: at 65.91% examples, 72668 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:21:07,931 : INFO : EPOCH 25 - PROGRESS: at 79.63% examples, 73119 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:21:08,949 : INFO : EPOCH 25 - PROGRESS: at 92.34% examples, 72622 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:21:09,381 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:21:09,412 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:21:09,442 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:21:09,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:21:09,445 : INFO : EPOCH - 25 : training on 2193663 raw words (562544 effective words) took 7.7s, 73460 effective words/s\n",
      "2018-04-16 22:21:09,447 : INFO : training on a 54841575 raw words (14050266 effective words) took 202.2s, 69491 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed run number 2 of 2 runs total\n",
      "AUC score: 0.9279\n",
      "Training for this run took 3.5 minutes\n",
      "\n",
      "\n",
      "Total training time for all runs: 0.11 hours\n",
      "Best AUC value: 0.928385\n",
      "Paramters for best AUC value: {'min_alpha': 0.0001, 'iter': 25, 'sample': 1e-05, 'size': 300, 'negative': 5, 'alpha': 0.025, 'window': 5, 'min_count': 1, 'dm': 0, 'workers': 4, 'hs': 0, 'dbow_words': 1}\n"
     ]
    }
   ],
   "source": [
    "# create list to score ROC AUC scores and their model parameters\n",
    "params_and_errors = []\n",
    "\n",
    "print (\"Starting first run of\", len(parameters), \"runs\")\n",
    "total_time = 0\n",
    "for run_number, pars in enumerate(parameters): \n",
    "    params = {'dm':pars[0], 'size':pars[1], 'window':pars[2], \n",
    "              'alpha':pars[3], 'min_alpha':pars[4], 'min_count':pars[5],\n",
    "              'sample':pars[6], 'workers':pars[7], 'hs':pars[8],\n",
    "              'negative':pars[9], 'dbow_words':pars[10], 'iter':pars[11]}\n",
    "    with qu.elapsed_timer() as elapsed:\n",
    "        model = gensim.models.doc2vec.Doc2Vec(documents=all_docs, **params)\n",
    "        AUC_value = qu.calculate_AUC(model, doc_names_and_duplicate_class)\n",
    "        duration = '%.1f' % elapsed()\n",
    "        # save time to complete computation\n",
    "        m, s = divmod(float(duration), 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        time_string = \"%dh %02dm %02ds\" % (h, m, s)\n",
    "        params_and_errors.append((params, AUC_value, time_string))\n",
    "        total_time += float(duration)\n",
    "        print ()\n",
    "        print (\"Completed run number\", run_number + 1, \"of\", len(parameters), \"runs total\")\n",
    "        print (\"AUC score:\", round(AUC_value, 4))\n",
    "        print (\"Training for this run took\", round(float(duration)/60.,1), \"minutes\")\n",
    "\n",
    "best_AUC = max([x[1] for x in params_and_errors])\n",
    "print()\n",
    "print()\n",
    "print (\"Total training time for all runs:\", round(float(total_time)/3600.,2), \"hours\")\n",
    "print (\"Best AUC value:\", round(best_AUC, 6))\n",
    "print (\"Paramters for best AUC value:\", [x[0] for x in params_and_errors if x[1] == best_AUC][0]\n",
    ")\n",
    "# convert params and errors into easy-to-read pandas dataframe\n",
    "params_df = pd.DataFrame([x[0] for x in params_and_errors])\n",
    "params_df[\"AUC\"] = pd.Series([x[1] for x in params_and_errors])\n",
    "params_df[\"num_doc_pairs\"] = pd.Series([len(all_docs) for _ in range(len(params_and_errors))])\n",
    "params_df[\"compute_time\"] = pd.Series([x[2] for x in params_and_errors])\n",
    "params_df.sort_values(\"AUC\", ascending=False, inplace=True)\n",
    "\n",
    "# write parameter values to csv - append if this csv already exists\n",
    "header=True\n",
    "if os.path.isfile(parameters_and_errors_name):\n",
    "    header=False\n",
    "params_df.to_csv(parameters_and_errors_name, header=header, index=False, mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>dbow_words</th>\n",
       "      <th>dm</th>\n",
       "      <th>hs</th>\n",
       "      <th>iter</th>\n",
       "      <th>min_alpha</th>\n",
       "      <th>min_count</th>\n",
       "      <th>negative</th>\n",
       "      <th>sample</th>\n",
       "      <th>size</th>\n",
       "      <th>window</th>\n",
       "      <th>workers</th>\n",
       "      <th>AUC</th>\n",
       "      <th>num_doc_pairs</th>\n",
       "      <th>compute_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.928385</td>\n",
       "      <td>160680</td>\n",
       "      <td>0h 03m 16s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927865</td>\n",
       "      <td>160680</td>\n",
       "      <td>0h 03m 29s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  dbow_words  dm  hs  iter  min_alpha  min_count  negative   sample  \\\n",
       "0  0.025           1   0   0    25     0.0001          1         5  0.00001   \n",
       "1  0.025           1   0   0    25     0.0001          5         5  0.00001   \n",
       "\n",
       "   size  window  workers       AUC  num_doc_pairs compute_time  \n",
       "0   300       5        4  0.928385         160680   0h 03m 16s  \n",
       "1   300       5        4  0.927865         160680   0h 03m 29s  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_count</th>\n",
       "      <th>AUC</th>\n",
       "      <th>compute_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.928385</td>\n",
       "      <td>0h 03m 16s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.927865</td>\n",
       "      <td>0h 03m 29s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_count       AUC compute_time\n",
       "0          1  0.928385   0h 03m 16s\n",
       "1          5  0.927865   0h 03m 29s"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df.loc[:, (params_df != params_df.ix[0]).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in paramater file to see what has been done before\n",
    "all_params_df = pd.read_csv(parameters_and_errors_name)\n",
    "all_params_df.sort_values(\"AUC\", ascending=False, inplace=True)\n",
    "# drop duplicate rows (not including AUC scores, which might vary slightly due to randomness)\n",
    "dup_columns = [u'alpha', u'dbow_words', u'dm', u'hs', u'iter', u'min_alpha',\n",
    "       u'min_count', u'negative', u'sample', u'size', u'window', u'workers',\n",
    "       u'num_doc_pairs']\n",
    "all_params_df.drop_duplicates(subset=dup_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>dbow_words</th>\n",
       "      <th>dm</th>\n",
       "      <th>hs</th>\n",
       "      <th>iter</th>\n",
       "      <th>min_alpha</th>\n",
       "      <th>min_count</th>\n",
       "      <th>negative</th>\n",
       "      <th>sample</th>\n",
       "      <th>size</th>\n",
       "      <th>window</th>\n",
       "      <th>workers</th>\n",
       "      <th>AUC</th>\n",
       "      <th>num_doc_pairs</th>\n",
       "      <th>compute_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934298</td>\n",
       "      <td>200848</td>\n",
       "      <td>0h 03m 54s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.933632</td>\n",
       "      <td>200848</td>\n",
       "      <td>0h 04m 21s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.928385</td>\n",
       "      <td>160680</td>\n",
       "      <td>0h 03m 16s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927865</td>\n",
       "      <td>160680</td>\n",
       "      <td>0h 03m 29s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  dbow_words  dm  hs  iter  min_alpha  min_count  negative   sample  \\\n",
       "2  0.025           1   0   0    25     0.0001          1         5  0.00001   \n",
       "3  0.025           1   0   0    25     0.0001          5         5  0.00001   \n",
       "6  0.025           1   0   0    25     0.0001          1         5  0.00001   \n",
       "7  0.025           1   0   0    25     0.0001          5         5  0.00001   \n",
       "\n",
       "   size  window  workers       AUC  num_doc_pairs compute_time  \n",
       "2   300       5        4  0.934298         200848   0h 03m 54s  \n",
       "3   300       5        4  0.933632         200848   0h 04m 21s  \n",
       "6   300       5        4  0.928385         160680   0h 03m 16s  \n",
       "7   300       5        4  0.927865         160680   0h 03m 29s  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docsT = (all_docs, all_docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/gensim/models/doc2vec.py:362: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2018-04-16 22:31:46,551 : INFO : collecting all words and their counts\n",
      "2018-04-16 22:31:46,552 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-04-16 22:31:46,662 : INFO : PROGRESS: at example #10000, processed 138247 words (1260203/s), 5994 word types, 10000 tags\n",
      "2018-04-16 22:31:46,772 : INFO : PROGRESS: at example #20000, processed 274419 words (1250777/s), 7051 word types, 20000 tags\n",
      "2018-04-16 22:31:46,874 : INFO : PROGRESS: at example #30000, processed 411567 words (1351450/s), 7634 word types, 30000 tags\n",
      "2018-04-16 22:31:46,966 : INFO : PROGRESS: at example #40000, processed 549845 words (1530889/s), 7918 word types, 40000 tags\n",
      "2018-04-16 22:31:47,060 : INFO : PROGRESS: at example #50000, processed 686582 words (1461640/s), 8085 word types, 50000 tags\n",
      "2018-04-16 22:31:47,154 : INFO : PROGRESS: at example #60000, processed 824684 words (1482775/s), 8190 word types, 60000 tags\n",
      "2018-04-16 22:31:47,246 : INFO : PROGRESS: at example #70000, processed 961911 words (1511278/s), 8283 word types, 70000 tags\n",
      "2018-04-16 22:31:47,341 : INFO : PROGRESS: at example #80000, processed 1098018 words (1452409/s), 8342 word types, 80000 tags\n",
      "2018-04-16 22:31:47,439 : INFO : PROGRESS: at example #90000, processed 1234905 words (1419336/s), 8404 word types, 90000 tags\n",
      "2018-04-16 22:31:47,532 : INFO : PROGRESS: at example #100000, processed 1369538 words (1474037/s), 8439 word types, 100000 tags\n",
      "2018-04-16 22:31:47,656 : INFO : PROGRESS: at example #110000, processed 1504169 words (1091975/s), 8451 word types, 110000 tags\n",
      "2018-04-16 22:31:48,114 : INFO : PROGRESS: at example #120000, processed 1640680 words (299001/s), 8452 word types, 120000 tags\n",
      "2018-04-16 22:31:48,277 : INFO : PROGRESS: at example #130000, processed 1777013 words (842578/s), 8453 word types, 130000 tags\n",
      "2018-04-16 22:31:48,399 : INFO : PROGRESS: at example #140000, processed 1913252 words (1127651/s), 8455 word types, 140000 tags\n",
      "2018-04-16 22:31:48,508 : INFO : PROGRESS: at example #150000, processed 2050305 words (1261501/s), 8455 word types, 150000 tags\n",
      "2018-04-16 22:31:48,605 : INFO : PROGRESS: at example #160000, processed 2184382 words (1398953/s), 8456 word types, 160000 tags\n",
      "2018-04-16 22:31:48,612 : INFO : collected 8456 word types and 160680 unique tags from a corpus of 160680 examples and 2193663 words\n",
      "2018-04-16 22:31:48,614 : INFO : Loading a fresh vocabulary\n",
      "2018-04-16 22:31:48,649 : INFO : min_count=1 retains 8456 unique words (100% of original 8456, drops 0)\n",
      "2018-04-16 22:31:48,650 : INFO : min_count=1 leaves 2193663 word corpus (100% of original 2193663, drops 0)\n",
      "2018-04-16 22:31:48,680 : INFO : deleting the raw counts dictionary of 8456 items\n",
      "2018-04-16 22:31:48,683 : INFO : sample=5e-05 downsamples 930 most-common words\n",
      "2018-04-16 22:31:48,686 : INFO : downsampling leaves estimated 769477 word corpus (35.1% of prior 2193663)\n",
      "2018-04-16 22:31:48,722 : INFO : estimated required memory for 8456 words and 300 dimensions: 249474400 bytes\n",
      "2018-04-16 22:31:48,723 : INFO : resetting layer weights\n",
      "2018-04-16 22:31:51,719 : INFO : training model with 4 workers on 8456 vocabulary and 300 features, using sg=1 hs=0 sample=5e-05 negative=5 window=5\n",
      "2018-04-16 22:31:52,777 : INFO : EPOCH 1 - PROGRESS: at 11.30% examples, 101376 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:31:53,803 : INFO : EPOCH 1 - PROGRESS: at 21.75% examples, 98504 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:31:54,821 : INFO : EPOCH 1 - PROGRESS: at 31.69% examples, 96401 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:31:55,866 : INFO : EPOCH 1 - PROGRESS: at 43.90% examples, 99918 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:31:56,886 : INFO : EPOCH 1 - PROGRESS: at 54.83% examples, 99921 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:31:57,902 : INFO : EPOCH 1 - PROGRESS: at 66.37% examples, 100492 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:31:58,956 : INFO : EPOCH 1 - PROGRESS: at 76.89% examples, 99211 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:00,021 : INFO : EPOCH 1 - PROGRESS: at 86.44% examples, 97138 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:01,091 : INFO : EPOCH 1 - PROGRESS: at 98.39% examples, 97732 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-16 22:32:01,138 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:32:01,171 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:32:01,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:32:01,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:32:01,187 : INFO : EPOCH - 1 : training on 2193663 raw words (929996 effective words) took 9.5s, 98315 effective words/s\n",
      "2018-04-16 22:32:02,240 : INFO : EPOCH 2 - PROGRESS: at 10.84% examples, 97908 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:03,246 : INFO : EPOCH 2 - PROGRESS: at 21.75% examples, 99879 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:04,253 : INFO : EPOCH 2 - PROGRESS: at 32.15% examples, 99158 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:05,266 : INFO : EPOCH 2 - PROGRESS: at 43.44% examples, 100668 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:06,291 : INFO : EPOCH 2 - PROGRESS: at 55.75% examples, 102953 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:07,298 : INFO : EPOCH 2 - PROGRESS: at 65.44% examples, 100417 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:08,351 : INFO : EPOCH 2 - PROGRESS: at 76.42% examples, 99713 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:09,362 : INFO : EPOCH 2 - PROGRESS: at 87.82% examples, 100252 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:10,343 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:32:10,378 : INFO : EPOCH 2 - PROGRESS: at 99.30% examples, 100624 words/s, in_qsize 2, out_qsize 1\n",
      "2018-04-16 22:32:10,380 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:32:10,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:32:10,407 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:32:10,408 : INFO : EPOCH - 2 : training on 2193663 raw words (930372 effective words) took 9.2s, 101006 effective words/s\n",
      "2018-04-16 22:32:11,477 : INFO : EPOCH 3 - PROGRESS: at 9.50% examples, 84457 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:12,489 : INFO : EPOCH 3 - PROGRESS: at 19.95% examples, 90343 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:13,531 : INFO : EPOCH 3 - PROGRESS: at 31.25% examples, 94497 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:14,570 : INFO : EPOCH 3 - PROGRESS: at 40.70% examples, 92384 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:15,648 : INFO : EPOCH 3 - PROGRESS: at 51.65% examples, 92869 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:16,657 : INFO : EPOCH 3 - PROGRESS: at 59.91% examples, 90038 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:17,664 : INFO : EPOCH 3 - PROGRESS: at 70.96% examples, 91445 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:18,671 : INFO : EPOCH 3 - PROGRESS: at 79.63% examples, 89936 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:19,688 : INFO : EPOCH 3 - PROGRESS: at 91.46% examples, 91853 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:20,345 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:32:20,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:32:20,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:32:20,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:32:20,416 : INFO : EPOCH - 3 : training on 2193663 raw words (929876 effective words) took 10.0s, 92996 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:32:21,464 : INFO : EPOCH 4 - PROGRESS: at 10.38% examples, 94661 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:22,467 : INFO : EPOCH 4 - PROGRESS: at 20.84% examples, 96168 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:23,524 : INFO : EPOCH 4 - PROGRESS: at 31.25% examples, 95087 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:24,531 : INFO : EPOCH 4 - PROGRESS: at 42.98% examples, 98733 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:25,533 : INFO : EPOCH 4 - PROGRESS: at 53.92% examples, 99294 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:26,536 : INFO : EPOCH 4 - PROGRESS: at 64.53% examples, 98832 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:27,559 : INFO : EPOCH 4 - PROGRESS: at 74.14% examples, 97029 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:28,603 : INFO : EPOCH 4 - PROGRESS: at 86.89% examples, 99020 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:29,530 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:32:29,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:32:29,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:32:29,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:32:29,593 : INFO : EPOCH - 4 : training on 2193663 raw words (929767 effective words) took 9.2s, 101449 effective words/s\n",
      "2018-04-16 22:32:30,643 : INFO : EPOCH 5 - PROGRESS: at 10.40% examples, 94684 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:31,656 : INFO : EPOCH 5 - PROGRESS: at 20.84% examples, 95760 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:32,687 : INFO : EPOCH 5 - PROGRESS: at 32.15% examples, 98405 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:33,746 : INFO : EPOCH 5 - PROGRESS: at 42.07% examples, 95832 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:34,791 : INFO : EPOCH 5 - PROGRESS: at 53.02% examples, 96231 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:35,811 : INFO : EPOCH 5 - PROGRESS: at 63.13% examples, 95312 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:36,835 : INFO : EPOCH 5 - PROGRESS: at 75.05% examples, 96963 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:37,886 : INFO : EPOCH 5 - PROGRESS: at 86.44% examples, 97341 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:38,906 : INFO : EPOCH 5 - PROGRESS: at 97.93% examples, 98000 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 22:32:38,943 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:32:39,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:32:39,023 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:32:39,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:32:39,028 : INFO : EPOCH - 5 : training on 2193663 raw words (930114 effective words) took 9.4s, 98775 effective words/s\n",
      "2018-04-16 22:32:40,047 : INFO : EPOCH 6 - PROGRESS: at 9.48% examples, 88412 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:41,102 : INFO : EPOCH 6 - PROGRESS: at 20.84% examples, 94920 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:42,115 : INFO : EPOCH 6 - PROGRESS: at 32.15% examples, 98371 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:43,158 : INFO : EPOCH 6 - PROGRESS: at 42.98% examples, 98301 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:44,208 : INFO : EPOCH 6 - PROGRESS: at 53.02% examples, 96479 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:45,233 : INFO : EPOCH 6 - PROGRESS: at 63.60% examples, 96170 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:46,331 : INFO : EPOCH 6 - PROGRESS: at 75.05% examples, 96113 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:47,357 : INFO : EPOCH 6 - PROGRESS: at 86.92% examples, 97426 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:48,392 : INFO : EPOCH 6 - PROGRESS: at 98.39% examples, 97891 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-16 22:32:48,416 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:32:48,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:32:48,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:32:48,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:32:48,472 : INFO : EPOCH - 6 : training on 2193663 raw words (930713 effective words) took 9.4s, 98640 effective words/s\n",
      "2018-04-16 22:32:49,499 : INFO : EPOCH 7 - PROGRESS: at 11.31% examples, 104298 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:50,529 : INFO : EPOCH 7 - PROGRESS: at 23.55% examples, 108168 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:51,567 : INFO : EPOCH 7 - PROGRESS: at 33.50% examples, 102206 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:32:52,611 : INFO : EPOCH 7 - PROGRESS: at 43.90% examples, 100188 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:53,655 : INFO : EPOCH 7 - PROGRESS: at 53.48% examples, 97211 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:54,712 : INFO : EPOCH 7 - PROGRESS: at 62.20% examples, 93522 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:55,716 : INFO : EPOCH 7 - PROGRESS: at 72.79% examples, 93908 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:56,740 : INFO : EPOCH 7 - PROGRESS: at 84.63% examples, 95527 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:57,755 : INFO : EPOCH 7 - PROGRESS: at 96.99% examples, 97261 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:32:57,933 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:32:57,951 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:32:57,975 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:32:57,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:32:57,982 : INFO : EPOCH - 7 : training on 2193663 raw words (929545 effective words) took 9.5s, 97838 effective words/s\n",
      "2018-04-16 22:32:58,999 : INFO : EPOCH 8 - PROGRESS: at 9.48% examples, 89217 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:00,014 : INFO : EPOCH 8 - PROGRESS: at 20.40% examples, 94932 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:01,033 : INFO : EPOCH 8 - PROGRESS: at 30.80% examples, 95476 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:02,065 : INFO : EPOCH 8 - PROGRESS: at 41.18% examples, 95341 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:03,070 : INFO : EPOCH 8 - PROGRESS: at 52.10% examples, 96643 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:04,089 : INFO : EPOCH 8 - PROGRESS: at 63.13% examples, 97079 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:05,114 : INFO : EPOCH 8 - PROGRESS: at 73.25% examples, 96042 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:06,126 : INFO : EPOCH 8 - PROGRESS: at 84.63% examples, 97021 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:07,134 : INFO : EPOCH 8 - PROGRESS: at 95.16% examples, 96882 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:07,477 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:33:07,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:33:07,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:33:07,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:33:07,534 : INFO : EPOCH - 8 : training on 2193663 raw words (929920 effective words) took 9.5s, 97502 effective words/s\n",
      "2018-04-16 22:33:08,668 : INFO : EPOCH 9 - PROGRESS: at 11.31% examples, 94479 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:09,719 : INFO : EPOCH 9 - PROGRESS: at 21.75% examples, 93891 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:10,784 : INFO : EPOCH 9 - PROGRESS: at 32.60% examples, 94635 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:11,858 : INFO : EPOCH 9 - PROGRESS: at 43.45% examples, 94823 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:12,931 : INFO : EPOCH 9 - PROGRESS: at 54.38% examples, 94898 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:14,016 : INFO : EPOCH 9 - PROGRESS: at 65.89% examples, 95251 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:15,042 : INFO : EPOCH 9 - PROGRESS: at 77.34% examples, 96208 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:33:16,104 : INFO : EPOCH 9 - PROGRESS: at 89.19% examples, 97036 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:16,883 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:33:16,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:33:16,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:33:16,924 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:33:16,925 : INFO : EPOCH - 9 : training on 2193663 raw words (930025 effective words) took 9.4s, 99144 effective words/s\n",
      "2018-04-16 22:33:17,949 : INFO : EPOCH 10 - PROGRESS: at 11.31% examples, 104736 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:18,964 : INFO : EPOCH 10 - PROGRESS: at 24.43% examples, 113358 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:20,055 : INFO : EPOCH 10 - PROGRESS: at 36.21% examples, 109402 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:21,126 : INFO : EPOCH 10 - PROGRESS: at 48.93% examples, 110012 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:22,197 : INFO : EPOCH 10 - PROGRESS: at 59.88% examples, 106782 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:23,205 : INFO : EPOCH 10 - PROGRESS: at 72.33% examples, 107753 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:24,226 : INFO : EPOCH 10 - PROGRESS: at 83.26% examples, 106505 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:25,255 : INFO : EPOCH 10 - PROGRESS: at 93.26% examples, 104410 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:25,834 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:33:25,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:33:25,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:33:25,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:33:25,878 : INFO : EPOCH - 10 : training on 2193663 raw words (930065 effective words) took 8.9s, 103997 effective words/s\n",
      "2018-04-16 22:33:26,965 : INFO : EPOCH 11 - PROGRESS: at 9.94% examples, 87581 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:33:27,979 : INFO : EPOCH 11 - PROGRESS: at 21.29% examples, 96124 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:28,983 : INFO : EPOCH 11 - PROGRESS: at 32.15% examples, 98136 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:30,024 : INFO : EPOCH 11 - PROGRESS: at 43.90% examples, 100277 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:31,031 : INFO : EPOCH 11 - PROGRESS: at 55.28% examples, 101229 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:32,040 : INFO : EPOCH 11 - PROGRESS: at 66.82% examples, 101754 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:33,136 : INFO : EPOCH 11 - PROGRESS: at 78.71% examples, 101415 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:34,179 : INFO : EPOCH 11 - PROGRESS: at 90.10% examples, 101293 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:34,885 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:33:34,934 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:33:34,936 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:33:34,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:33:34,943 : INFO : EPOCH - 11 : training on 2193663 raw words (930071 effective words) took 9.0s, 102811 effective words/s\n",
      "2018-04-16 22:33:35,985 : INFO : EPOCH 12 - PROGRESS: at 11.31% examples, 103898 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:36,996 : INFO : EPOCH 12 - PROGRESS: at 22.21% examples, 102614 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:38,064 : INFO : EPOCH 12 - PROGRESS: at 33.05% examples, 100360 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:39,114 : INFO : EPOCH 12 - PROGRESS: at 44.36% examples, 100683 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:33:40,206 : INFO : EPOCH 12 - PROGRESS: at 54.83% examples, 98353 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:41,285 : INFO : EPOCH 12 - PROGRESS: at 65.91% examples, 97551 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:42,308 : INFO : EPOCH 12 - PROGRESS: at 77.34% examples, 98227 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:43,323 : INFO : EPOCH 12 - PROGRESS: at 90.10% examples, 100400 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:44,007 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:33:44,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:33:44,069 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:33:44,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:33:44,086 : INFO : EPOCH - 12 : training on 2193663 raw words (930648 effective words) took 9.1s, 101970 effective words/s\n",
      "2018-04-16 22:33:45,122 : INFO : EPOCH 13 - PROGRESS: at 11.76% examples, 109116 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:46,153 : INFO : EPOCH 13 - PROGRESS: at 23.55% examples, 108364 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:47,183 : INFO : EPOCH 13 - PROGRESS: at 33.94% examples, 103949 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:33:48,203 : INFO : EPOCH 13 - PROGRESS: at 45.75% examples, 105122 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:49,228 : INFO : EPOCH 13 - PROGRESS: at 56.66% examples, 103925 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:33:50,246 : INFO : EPOCH 13 - PROGRESS: at 67.75% examples, 103133 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:51,269 : INFO : EPOCH 13 - PROGRESS: at 78.71% examples, 102478 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:52,291 : INFO : EPOCH 13 - PROGRESS: at 90.10% examples, 102521 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:53,111 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:33:53,157 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:33:53,173 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:33:53,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:33:53,175 : INFO : EPOCH - 13 : training on 2193663 raw words (929763 effective words) took 9.1s, 102544 effective words/s\n",
      "2018-04-16 22:33:54,265 : INFO : EPOCH 14 - PROGRESS: at 11.31% examples, 99114 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:55,282 : INFO : EPOCH 14 - PROGRESS: at 23.55% examples, 106027 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:56,324 : INFO : EPOCH 14 - PROGRESS: at 34.84% examples, 104840 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:57,325 : INFO : EPOCH 14 - PROGRESS: at 44.36% examples, 101161 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:33:58,351 : INFO : EPOCH 14 - PROGRESS: at 54.83% examples, 100008 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:33:59,380 : INFO : EPOCH 14 - PROGRESS: at 66.37% examples, 100383 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:00,380 : INFO : EPOCH 14 - PROGRESS: at 77.35% examples, 100463 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:01,427 : INFO : EPOCH 14 - PROGRESS: at 89.65% examples, 101445 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:02,215 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:34:02,230 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:34:02,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:34:02,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:34:02,246 : INFO : EPOCH - 14 : training on 2193663 raw words (930459 effective words) took 9.1s, 102761 effective words/s\n",
      "2018-04-16 22:34:03,277 : INFO : EPOCH 15 - PROGRESS: at 9.02% examples, 83409 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:04,291 : INFO : EPOCH 15 - PROGRESS: at 20.40% examples, 94365 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:05,426 : INFO : EPOCH 15 - PROGRESS: at 30.78% examples, 91562 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:06,496 : INFO : EPOCH 15 - PROGRESS: at 42.07% examples, 93571 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:07,530 : INFO : EPOCH 15 - PROGRESS: at 53.02% examples, 94691 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:34:08,554 : INFO : EPOCH 15 - PROGRESS: at 64.06% examples, 95337 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:09,560 : INFO : EPOCH 15 - PROGRESS: at 73.70% examples, 94262 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:10,570 : INFO : EPOCH 15 - PROGRESS: at 83.26% examples, 93422 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:11,624 : INFO : EPOCH 15 - PROGRESS: at 92.81% examples, 92330 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:12,180 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:34:12,191 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:34:12,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:34:12,197 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:34:12,198 : INFO : EPOCH - 15 : training on 2193663 raw words (930780 effective words) took 9.9s, 93619 effective words/s\n",
      "2018-04-16 22:34:13,299 : INFO : EPOCH 16 - PROGRESS: at 11.31% examples, 98610 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:14,332 : INFO : EPOCH 16 - PROGRESS: at 23.99% examples, 106974 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:15,362 : INFO : EPOCH 16 - PROGRESS: at 34.84% examples, 104594 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:16,373 : INFO : EPOCH 16 - PROGRESS: at 42.99% examples, 97629 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:17,400 : INFO : EPOCH 16 - PROGRESS: at 53.48% examples, 97137 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:18,409 : INFO : EPOCH 16 - PROGRESS: at 63.13% examples, 95572 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:19,456 : INFO : EPOCH 16 - PROGRESS: at 74.62% examples, 96231 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:20,457 : INFO : EPOCH 16 - PROGRESS: at 86.44% examples, 97826 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:21,461 : INFO : EPOCH 16 - PROGRESS: at 97.46% examples, 98119 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 22:34:21,500 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:34:21,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:34:21,610 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:34:21,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:34:21,621 : INFO : EPOCH - 16 : training on 2193663 raw words (929923 effective words) took 9.4s, 98910 effective words/s\n",
      "2018-04-16 22:34:22,631 : INFO : EPOCH 17 - PROGRESS: at 8.59% examples, 80839 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:23,634 : INFO : EPOCH 17 - PROGRESS: at 18.58% examples, 87205 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:24,653 : INFO : EPOCH 17 - PROGRESS: at 29.44% examples, 91770 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:25,716 : INFO : EPOCH 17 - PROGRESS: at 41.18% examples, 94927 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:26,783 : INFO : EPOCH 17 - PROGRESS: at 52.10% examples, 95141 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:27,823 : INFO : EPOCH 17 - PROGRESS: at 61.74% examples, 93432 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:28,831 : INFO : EPOCH 17 - PROGRESS: at 73.69% examples, 95577 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:29,834 : INFO : EPOCH 17 - PROGRESS: at 85.09% examples, 96722 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:30,867 : INFO : EPOCH 17 - PROGRESS: at 97.46% examples, 98188 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 22:34:30,990 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:34:31,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:34:31,036 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:34:31,059 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:34:31,060 : INFO : EPOCH - 17 : training on 2193663 raw words (930357 effective words) took 9.4s, 98649 effective words/s\n",
      "2018-04-16 22:34:32,084 : INFO : EPOCH 18 - PROGRESS: at 9.94% examples, 92107 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:33,162 : INFO : EPOCH 18 - PROGRESS: at 19.94% examples, 89407 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:34,171 : INFO : EPOCH 18 - PROGRESS: at 30.34% examples, 91994 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:35,220 : INFO : EPOCH 18 - PROGRESS: at 40.71% examples, 92329 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:36,225 : INFO : EPOCH 18 - PROGRESS: at 50.75% examples, 92568 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:37,232 : INFO : EPOCH 18 - PROGRESS: at 61.28% examples, 93181 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:38,274 : INFO : EPOCH 18 - PROGRESS: at 73.25% examples, 94844 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:39,327 : INFO : EPOCH 18 - PROGRESS: at 83.73% examples, 94479 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:40,350 : INFO : EPOCH 18 - PROGRESS: at 93.73% examples, 93997 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:40,800 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:34:40,838 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:34:40,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:34:40,878 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:34:40,878 : INFO : EPOCH - 18 : training on 2193663 raw words (929796 effective words) took 9.8s, 94781 effective words/s\n",
      "2018-04-16 22:34:41,909 : INFO : EPOCH 19 - PROGRESS: at 8.59% examples, 79213 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:42,934 : INFO : EPOCH 19 - PROGRESS: at 18.12% examples, 83321 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:43,998 : INFO : EPOCH 19 - PROGRESS: at 28.09% examples, 85020 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:45,028 : INFO : EPOCH 19 - PROGRESS: at 36.19% examples, 82418 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:46,062 : INFO : EPOCH 19 - PROGRESS: at 44.84% examples, 81667 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:34:47,126 : INFO : EPOCH 19 - PROGRESS: at 54.38% examples, 82012 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:48,139 : INFO : EPOCH 19 - PROGRESS: at 63.60% examples, 82157 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:49,149 : INFO : EPOCH 19 - PROGRESS: at 73.70% examples, 83277 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:50,168 : INFO : EPOCH 19 - PROGRESS: at 84.18% examples, 84588 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:51,235 : INFO : EPOCH 19 - PROGRESS: at 94.68% examples, 85196 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:51,568 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:34:51,577 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:34:51,593 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:34:51,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:34:51,599 : INFO : EPOCH - 19 : training on 2193663 raw words (930273 effective words) took 10.7s, 86854 effective words/s\n",
      "2018-04-16 22:34:52,686 : INFO : EPOCH 20 - PROGRESS: at 11.31% examples, 98911 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:53,687 : INFO : EPOCH 20 - PROGRESS: at 22.66% examples, 102623 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:54,728 : INFO : EPOCH 20 - PROGRESS: at 34.84% examples, 105410 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:55,757 : INFO : EPOCH 20 - PROGRESS: at 45.74% examples, 103995 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:56,836 : INFO : EPOCH 20 - PROGRESS: at 55.72% examples, 100282 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:57,845 : INFO : EPOCH 20 - PROGRESS: at 66.37% examples, 99583 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:58,856 : INFO : EPOCH 20 - PROGRESS: at 75.96% examples, 97828 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:34:59,883 : INFO : EPOCH 20 - PROGRESS: at 87.37% examples, 98393 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:00,885 : INFO : EPOCH 20 - PROGRESS: at 97.93% examples, 98175 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 22:35:00,996 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 22:35:01,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:35:01,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:35:01,040 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:35:01,041 : INFO : EPOCH - 20 : training on 2193663 raw words (929622 effective words) took 9.4s, 98579 effective words/s\n",
      "2018-04-16 22:35:02,067 : INFO : EPOCH 21 - PROGRESS: at 9.94% examples, 92541 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:03,105 : INFO : EPOCH 21 - PROGRESS: at 20.84% examples, 95705 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:04,168 : INFO : EPOCH 21 - PROGRESS: at 32.60% examples, 98753 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:05,186 : INFO : EPOCH 21 - PROGRESS: at 43.44% examples, 99220 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:06,191 : INFO : EPOCH 21 - PROGRESS: at 54.83% examples, 100550 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:07,202 : INFO : EPOCH 21 - PROGRESS: at 66.82% examples, 101823 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:08,233 : INFO : EPOCH 21 - PROGRESS: at 77.35% examples, 100631 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:09,290 : INFO : EPOCH 21 - PROGRESS: at 88.74% examples, 100449 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:10,191 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:35:10,195 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:35:10,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:35:10,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:35:10,224 : INFO : EPOCH - 21 : training on 2193663 raw words (930564 effective words) took 9.2s, 101509 effective words/s\n",
      "2018-04-16 22:35:11,349 : INFO : EPOCH 22 - PROGRESS: at 11.31% examples, 96356 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:12,358 : INFO : EPOCH 22 - PROGRESS: at 23.09% examples, 102871 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:13,374 : INFO : EPOCH 22 - PROGRESS: at 32.60% examples, 98101 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:14,407 : INFO : EPOCH 22 - PROGRESS: at 42.98% examples, 97344 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:15,463 : INFO : EPOCH 22 - PROGRESS: at 54.38% examples, 97980 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:16,513 : INFO : EPOCH 22 - PROGRESS: at 67.28% examples, 100325 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:17,513 : INFO : EPOCH 22 - PROGRESS: at 77.80% examples, 99804 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:18,528 : INFO : EPOCH 22 - PROGRESS: at 89.65% examples, 100771 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:19,311 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:35:19,331 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:35:19,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:35:19,378 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:35:19,380 : INFO : EPOCH - 22 : training on 2193663 raw words (929746 effective words) took 9.1s, 101795 effective words/s\n",
      "2018-04-16 22:35:20,410 : INFO : EPOCH 23 - PROGRESS: at 10.40% examples, 96003 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:21,413 : INFO : EPOCH 23 - PROGRESS: at 19.50% examples, 90539 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:22,429 : INFO : EPOCH 23 - PROGRESS: at 29.44% examples, 91176 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:23,456 : INFO : EPOCH 23 - PROGRESS: at 39.33% examples, 91176 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:24,464 : INFO : EPOCH 23 - PROGRESS: at 49.38% examples, 91679 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:25,488 : INFO : EPOCH 23 - PROGRESS: at 60.35% examples, 92825 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:26,497 : INFO : EPOCH 23 - PROGRESS: at 71.42% examples, 93832 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:27,504 : INFO : EPOCH 23 - PROGRESS: at 83.73% examples, 96190 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:28,522 : INFO : EPOCH 23 - PROGRESS: at 94.68% examples, 96538 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:28,876 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:35:28,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:35:28,917 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:35:28,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:35:28,923 : INFO : EPOCH - 23 : training on 2193663 raw words (930372 effective words) took 9.5s, 97591 effective words/s\n",
      "2018-04-16 22:35:29,932 : INFO : EPOCH 24 - PROGRESS: at 9.94% examples, 93436 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:30,959 : INFO : EPOCH 24 - PROGRESS: at 19.04% examples, 88221 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:31,960 : INFO : EPOCH 24 - PROGRESS: at 29.44% examples, 91548 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:32,984 : INFO : EPOCH 24 - PROGRESS: at 38.44% examples, 89435 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:33,986 : INFO : EPOCH 24 - PROGRESS: at 48.48% examples, 90333 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:35,028 : INFO : EPOCH 24 - PROGRESS: at 58.53% examples, 90111 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:36,155 : INFO : EPOCH 24 - PROGRESS: at 68.67% examples, 88875 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:37,208 : INFO : EPOCH 24 - PROGRESS: at 78.25% examples, 88225 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:38,208 : INFO : EPOCH 24 - PROGRESS: at 87.83% examples, 88225 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:39,230 : INFO : EPOCH 24 - PROGRESS: at 98.39% examples, 88851 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-16 22:35:39,252 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:35:39,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:35:39,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:35:39,299 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:35:39,300 : INFO : EPOCH - 24 : training on 2193663 raw words (929983 effective words) took 10.4s, 89691 effective words/s\n",
      "2018-04-16 22:35:40,333 : INFO : EPOCH 25 - PROGRESS: at 9.50% examples, 87392 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:41,363 : INFO : EPOCH 25 - PROGRESS: at 20.84% examples, 95614 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:42,366 : INFO : EPOCH 25 - PROGRESS: at 30.80% examples, 95030 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:43,385 : INFO : EPOCH 25 - PROGRESS: at 40.71% examples, 94242 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:44,391 : INFO : EPOCH 25 - PROGRESS: at 50.75% examples, 94085 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:45,443 : INFO : EPOCH 25 - PROGRESS: at 61.75% examples, 94441 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:46,466 : INFO : EPOCH 25 - PROGRESS: at 72.79% examples, 95033 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 22:35:47,521 : INFO : EPOCH 25 - PROGRESS: at 83.73% examples, 95121 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:48,544 : INFO : EPOCH 25 - PROGRESS: at 96.07% examples, 96862 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 22:35:48,781 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 22:35:48,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 22:35:48,856 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 22:35:48,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 22:35:48,862 : INFO : EPOCH - 25 : training on 2193663 raw words (930719 effective words) took 9.6s, 97420 effective words/s\n",
      "2018-04-16 22:35:48,863 : INFO : training on a 54841575 raw words (23253469 effective words) took 237.1s, 98059 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.9552\n",
      "Training for this run took 4.1 minutes\n"
     ]
    }
   ],
   "source": [
    "best_params = {'dm':0, 'size':300, 'window':5, \n",
    "              'alpha':.025, 'min_alpha':.0001, 'min_count':1,\n",
    "              'sample':5e-5, 'workers':cores, 'hs':0,\n",
    "              'negative':5, 'dbow_words':1, 'iter':25}\n",
    "with qu.elapsed_timer() as elapsed:\n",
    "    model = gensim.models.doc2vec.Doc2Vec(documents=all_docs, **best_params)\n",
    "    AUC_value = qu.calculate_AUC(model, doc_names_and_duplicate_class)\n",
    "    duration = '%.1f' % elapsed()\n",
    "    print (\"AUC score:\", round(AUC_value, 4))\n",
    "    print (\"Training for this run took\", round(float(duration)/60.,1), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params2 = {'dm':0, 'size':300, 'window':5, \n",
    "              'alpha':.025, 'min_alpha':.0001, 'min_count':1,\n",
    "              'sample':5e-5, 'workers':cores, 'hs':0,\n",
    "              'negative':5, 'dbow_words':1, 'iter':25}\n",
    "with qu.elapsed_timer() as elapsed:\n",
    "    model2 = gensim.models.doc2vec.Doc2Vec(documents=all_docs2, **best_params2)\n",
    "    AUC_value2 = qu.calculate_AUC(model2, doc_names_and_duplicate_class2)\n",
    "    duration2 = '%.1f' % elapsed()\n",
    "    print (\"AUC score2:\", round(AUC_value, 4))\n",
    "    print (\"Training for this run2 took\", round(float(duration2)/60.,1), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_target, y_pred = qu.get_model_distances_and_scores(model, doc_names_and_duplicate_class)\n",
    "qu.report_accuracy_prec_recall_F1(y_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_target2, y_pred2 = qu.get_model_distances_and_scores(model2, doc_names_and_duplicate_class2)\n",
    "qu.report_accuracy_prec_recall_F1(y_target2, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'dm':0, 'size':300, 'window':5, \n",
    "              'alpha':.025, 'min_alpha':.0001, 'min_count':1,\n",
    "              'sample':5e-5, 'workers':cores, 'hs':0,\n",
    "              'negative':5, 'dbow_words':1, 'iter':25}\n",
    "with qu.elapsed_timer() as elapsed:\n",
    "    model = gensim.models.doc2vec.Doc2Vec(documents=all_docs, **best_params)\n",
    "    AUC_value = qu.calculate_AUC(model, doc_names_and_duplicate_class)\n",
    "    duration = '%.1f' % elapsed()\n",
    "    print( \"AUC score:\", round(AUC_value, 4))\n",
    "    print (\"Training for this run took\", round(float(duration)/60.,1), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params2 = {'dm':0, 'size':300, 'window':5, \n",
    "              'alpha':.025, 'min_alpha':.0001, 'min_count':1,\n",
    "              'sample':5e-5, 'workers':cores, 'hs':0,\n",
    "              'negative':5, 'dbow_words':1, 'iter':25}\n",
    "with qu.elapsed_timer() as elapsed:\n",
    "    model2 = gensim.models.doc2vec.Doc2Vec(documents=all_docs2, **best_params2)\n",
    "    AUC_value = qu.calculate_AUC(model2, doc_names_and_duplicate_class2)\n",
    "    duration2 = '%.1f' % elapsed()\n",
    "    print( \"AUC score2:\", round(AUC_value, 4))\n",
    "    print (\"Training for this run2 took\", round(float(duration2)/60.,1), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you want to keep question vectors stored in dataframe containing \n",
    "# all the original data, can load in data currently being used and add document vectors to it if desired\n",
    "current_data1 = pd.read_csv(complete_data_dataframe, nrows=num_question_pairs)\n",
    "current_data2 = pd.read_csv(complete_data_dataframe2, nrows=num_question_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vectors added to current_data dataframe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add numpy doc2vec representation for each question (2 questions per row)\n",
    "# the documents in doc_names_and_duplicate_class are in same order as documents in current_data dataframe\n",
    "# (and current_data is read from complete_data_dataframe csv file)\n",
    "q1_vecs = []\n",
    "q2_vecs = []\n",
    "is_dup = []\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class)):\n",
    "    # get word vectors for each question and add to current_data dataframe\n",
    "    vec1_name = doc_names_and_duplicate_class[i][0]\n",
    "    vec2_name = doc_names_and_duplicate_class[i][1]\n",
    "    vec1 = model.docvecs[vec1_name]         \n",
    "    vec2 = model.docvecs[vec2_name] \n",
    "    q1_vecs.append(vec1)\n",
    "    q2_vecs.append(vec2)\n",
    "    is_dup.append(doc_names_and_duplicate_class[i][2])\n",
    "\n",
    "# sanity check that ensures document vectors match their text in dataframe - compare the duplicate \n",
    "# tags between current_data and doc_names_and_duplicate_class\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class)):\n",
    "    assert doc_names_and_duplicate_class[i][2] == current_data[\"is_duplicate\"][i], \"Error in aligning document \\\n",
    "                                                                              vectors with their text at index %d\" % i\n",
    "\n",
    "current_data1[\"q1_vecs\"] = pd.Series(q1_vecs)\n",
    "current_data1[\"q2_vecs\"] = pd.Series(q2_vecs)\n",
    "print (\"Document vectors added to current_data dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add numpy doc2vec representation for each question (2 questions per row)\n",
    "# the documents in doc_names_and_duplicate_class are in same order as documents in current_data dataframe\n",
    "# (and current_data is read from complete_data_dataframe csv file)\n",
    "q1_vecs2 = []\n",
    "q2_vecs2 = []\n",
    "is_dup2 = []\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class2)):\n",
    "    # get word vectors for each question and add to current_data dataframe\n",
    "    vec1_name2 = doc_names_and_duplicate_class2[i][0]\n",
    "    vec2_name2 = doc_names_and_duplicate_class2[i][1]\n",
    "    vec1 = model.docvecs[vec1_name2]         \n",
    "    vec2 = model.docvecs[vec2_name2] \n",
    "    q1_vecs2.append(vec1)\n",
    "    q2_vecs2.append(vec2)\n",
    "    is_dup2.append(doc_names_and_duplicate_class2[i][2])\n",
    "\n",
    "# sanity check that ensures document vectors match their text in dataframe - compare the duplicate \n",
    "# tags between current_data and doc_names_and_duplicate_class\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class2)):\n",
    "    assert doc_names_and_duplicate_class2[i][2] == current_data2[\"is_duplicate\"][i], \"Error in aligning document \\\n",
    "                                                                              vectors with their text at index %d\" % i\n",
    "\n",
    "current_data2[\"q1_vecs\"] = pd.Series(q1_vecs2)\n",
    "current_data2[\"q2_vecs\"] = pd.Series(q2_vecs2)\n",
    "print (\"Document vectors added to current_data dataframe2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/megoconnell/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create X_1, X_2 and y\n",
    "# X_1 is numpy array of q1 vectors\n",
    "# X_2 is numpy array of q2 vectors\n",
    "# y is array of target values\n",
    "\n",
    "# we will just use the already existing q1_vecs and q2_vecs lists\n",
    "X_1_d2v = np.array(q1_vecs)\n",
    "X_2_d2v = np.array(q2_vecs)\n",
    "TX_1_d2v = np.array(q1_vecs2)\n",
    "TX_2_d2v = np.array(q2_vecs2)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "num_classes = 2\n",
    "\n",
    "y_d2v = np_utils.to_categorical(np.array(is_dup), num_classes)\n",
    "Ty_d2v = np_utils.to_categorical(np.array(is_dup2), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# iterates over all files in a directory - the attribute rows tells how many rows of each file will be read\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname, rows=None):\n",
    "        self.dirname = dirname\n",
    "        self.rows = rows\n",
    " \n",
    "    def __iter__(self):\n",
    "        for filename in os.listdir(self.dirname):\n",
    "            for uid, line in enumerate(open(os.path.join(self.dirname, filename))):\n",
    "                if self.rows: \n",
    "                    if uid >= self.rows:\n",
    "                        break\n",
    "                yield line.split()\n",
    "\n",
    "# class to iterate through single file \n",
    "class OneFileSentences(object): \n",
    "    def __init__(self, filename, rows=None): \n",
    "        self.filename = filename\n",
    "        self.rows = rows\n",
    "    \n",
    "    def __iter__(self): \n",
    "        for uid, line in enumerate(open(self.filename)): \n",
    "            if self.rows: \n",
    "                if uid >= self.rows:\n",
    "                    break\n",
    "            yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "q1_doc_word2vecs = []\n",
    "q2_doc_word2vecs = []\n",
    "is_dup_doc_word2vecs = []\n",
    "\n",
    "q1_iterator = OneFileSentences(questions_folder_name + \"/\" + q1_file_name, rows=num_question_pairs)\n",
    "q2_iterator = OneFileSentences(questions_folder_name + \"/\" + q2_file_name, rows=num_question_pairs)\n",
    "\n",
    "for q1_sentence, q2_sentence in zip(q1_iterator, q2_iterator):\n",
    "    q1_vec = qu.make_question_vectors(model, q1_sentence) # \"model\" is name of doc2vec model trained above\n",
    "    q2_vec = qu.make_question_vectors(model, q2_sentence) \n",
    "    q1_doc_word2vecs.append(q1_vec)\n",
    "    q2_doc_word2vecs.append(q2_vec)\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class)):\n",
    "    is_dup_doc_word2vecs.append(doc_names_and_duplicate_class[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "q1_doc_word2vecs2 = []\n",
    "q2_doc_word2vecs2 = []\n",
    "is_dup_doc_word2vecs2 = []\n",
    "\n",
    "q1_iterator2 = OneFileSentences(questions_folder_name2 + \"/\" + q1_file_name2, rows=num_question_pairs)\n",
    "q2_iterator2 = OneFileSentences(questions_folder_name2 + \"/\" + q2_file_name2, rows=num_question_pairs)\n",
    "\n",
    "for q1_sentence, q2_sentence in zip(q1_iterator2, q2_iterator2):\n",
    "    q1_vec2 = qu.make_question_vectors(model2, q1_sentence2) # \"model\" is name of doc2vec model trained above\n",
    "    q2_vec2 = qu.make_question_vectors(model2, q2_sentence) \n",
    "    q1_doc_word2vecs2.append(q1_vec2)\n",
    "    q2_doc_word2vecs2.append(q2_vec2)\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class2)):\n",
    "    is_dup_doc_word2vecs2.append(doc_names_and_duplicate_class2[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_d_w2v = np.array(q1_doc_word2vecs)\n",
    "X_2_d_w2v = np.array(q2_doc_word2vecs)\n",
    "X_1_d_w2v2 = np.array(q1_doc_word2vecs2)\n",
    "X_2_d_w2v2 = np.array(q2_doc_word2vecs2)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "num_classes = 2\n",
    "\n",
    "y_d_w2v = np_utils.to_categorical(np.array(is_dup_doc_word2vecs), num_classes)\n",
    "y_d_w2v2 = np_utils.to_categorical2(np.array(is_dup_doc_word2vecs2), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare parameters from best document model for skip-gram model\n",
    "best_params = {'dm':0, 'size':300, 'window':5, \n",
    "              'alpha':.025, 'min_alpha':.0001, 'min_count':1,\n",
    "              'sample':5e-5, 'workers':cores, 'hs':0,\n",
    "              'negative':5, 'dbow_words':1, 'iter':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare parameters from best document model for skip-gram model\n",
    "best_params2 = {'dm':0, 'size':300, 'window':5, \n",
    "              'alpha':.025, 'min_alpha':.0001, 'min_count':1,\n",
    "              'sample':5e-5, 'workers':cores, 'hs':0,\n",
    "              'negative':5, 'dbow_words':1, 'iter':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 19:33:23,611 : INFO : collecting all words and their counts\n",
      "2018-04-16 19:33:23,620 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-16 19:33:23,716 : INFO : PROGRESS: at sentence #10000, processed 136251 words, keeping 6080 word types\n",
      "2018-04-16 19:33:23,808 : INFO : PROGRESS: at sentence #20000, processed 271792 words, keeping 7147 word types\n",
      "2018-04-16 19:33:23,913 : INFO : PROGRESS: at sentence #30000, processed 408224 words, keeping 7635 word types\n",
      "2018-04-16 19:33:23,993 : INFO : PROGRESS: at sentence #40000, processed 544937 words, keeping 7930 word types\n",
      "2018-04-16 19:33:24,067 : INFO : PROGRESS: at sentence #50000, processed 680772 words, keeping 8129 word types\n",
      "2018-04-16 19:33:24,155 : INFO : PROGRESS: at sentence #60000, processed 817908 words, keeping 8236 word types\n",
      "2018-04-16 19:33:24,228 : INFO : PROGRESS: at sentence #70000, processed 953832 words, keeping 8308 word types\n",
      "2018-04-16 19:33:24,311 : INFO : PROGRESS: at sentence #80000, processed 1091691 words, keeping 8374 word types\n",
      "2018-04-16 19:33:24,400 : INFO : PROGRESS: at sentence #90000, processed 1229691 words, keeping 8427 word types\n",
      "2018-04-16 19:33:24,487 : INFO : PROGRESS: at sentence #100000, processed 1366153 words, keeping 8458 word types\n",
      "2018-04-16 19:33:24,571 : INFO : PROGRESS: at sentence #110000, processed 1501430 words, keeping 8511 word types\n",
      "2018-04-16 19:33:24,674 : INFO : PROGRESS: at sentence #120000, processed 1635351 words, keeping 8544 word types\n",
      "2018-04-16 19:33:24,767 : INFO : PROGRESS: at sentence #130000, processed 1769968 words, keeping 8558 word types\n",
      "2018-04-16 19:33:24,863 : INFO : PROGRESS: at sentence #140000, processed 1904976 words, keeping 8563 word types\n",
      "2018-04-16 19:33:24,934 : INFO : PROGRESS: at sentence #150000, processed 2038063 words, keeping 8567 word types\n",
      "2018-04-16 19:33:25,004 : INFO : PROGRESS: at sentence #160000, processed 2171544 words, keeping 8569 word types\n",
      "2018-04-16 19:33:25,075 : INFO : PROGRESS: at sentence #170000, processed 2306495 words, keeping 8571 word types\n",
      "2018-04-16 19:33:25,167 : INFO : PROGRESS: at sentence #180000, processed 2442299 words, keeping 8573 word types\n",
      "2018-04-16 19:33:25,246 : INFO : PROGRESS: at sentence #190000, processed 2577885 words, keeping 8574 word types\n",
      "2018-04-16 19:33:25,335 : INFO : PROGRESS: at sentence #200000, processed 2712600 words, keeping 8574 word types\n",
      "2018-04-16 19:33:25,342 : INFO : collected 8574 word types from a corpus of 2724082 raw words and 200848 sentences\n",
      "2018-04-16 19:33:25,343 : INFO : Loading a fresh vocabulary\n",
      "2018-04-16 19:33:25,385 : INFO : min_count=1 retains 8574 unique words (100% of original 8574, drops 0)\n",
      "2018-04-16 19:33:25,387 : INFO : min_count=1 leaves 2724082 word corpus (100% of original 2724082, drops 0)\n",
      "2018-04-16 19:33:25,432 : INFO : deleting the raw counts dictionary of 8574 items\n",
      "2018-04-16 19:33:25,434 : INFO : sample=5e-05 downsamples 932 most-common words\n",
      "2018-04-16 19:33:25,435 : INFO : downsampling leaves estimated 962687 word corpus (35.3% of prior 2724082)\n",
      "2018-04-16 19:33:25,474 : INFO : estimated required memory for 8574 words and 300 dimensions: 24864600 bytes\n",
      "2018-04-16 19:33:25,474 : INFO : resetting layer weights\n",
      "2018-04-16 19:33:25,627 : INFO : training model with 4 workers on 8574 vocabulary and 300 features, using sg=1 hs=0 sample=5e-05 negative=5 window=5\n",
      "2018-04-16 19:33:26,635 : INFO : EPOCH 1 - PROGRESS: at 31.75% examples, 307839 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 19:33:27,639 : INFO : EPOCH 1 - PROGRESS: at 60.60% examples, 293471 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:28,647 : INFO : EPOCH 1 - PROGRESS: at 94.97% examples, 303423 words/s, in_qsize 8, out_qsize 0\n",
      "2018-04-16 19:33:28,774 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:28,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:28,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:28,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:28,809 : INFO : EPOCH - 1 : training on 2724082 raw words (963292 effective words) took 3.2s, 302947 effective words/s\n",
      "2018-04-16 19:33:29,816 : INFO : EPOCH 2 - PROGRESS: at 29.57% examples, 286950 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:30,818 : INFO : EPOCH 2 - PROGRESS: at 65.04% examples, 314615 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:31,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:31,671 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:31,685 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:31,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:31,688 : INFO : EPOCH - 2 : training on 2724082 raw words (961378 effective words) took 2.9s, 334249 effective words/s\n",
      "2018-04-16 19:33:32,701 : INFO : EPOCH 3 - PROGRESS: at 11.70% examples, 112888 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 19:33:33,724 : INFO : EPOCH 3 - PROGRESS: at 53.58% examples, 257425 words/s, in_qsize 3, out_qsize 2\n",
      "2018-04-16 19:33:34,735 : INFO : EPOCH 3 - PROGRESS: at 96.43% examples, 305172 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:34,797 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:34,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:34,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:34,815 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:34,816 : INFO : EPOCH - 3 : training on 2724082 raw words (962656 effective words) took 3.1s, 308002 effective words/s\n",
      "2018-04-16 19:33:35,834 : INFO : EPOCH 4 - PROGRESS: at 36.50% examples, 351800 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 19:33:36,848 : INFO : EPOCH 4 - PROGRESS: at 76.18% examples, 363980 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:37,377 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:37,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:37,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:37,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:37,396 : INFO : EPOCH - 4 : training on 2724082 raw words (963533 effective words) took 2.6s, 374228 effective words/s\n",
      "2018-04-16 19:33:38,405 : INFO : EPOCH 5 - PROGRESS: at 36.13% examples, 349889 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:39,409 : INFO : EPOCH 5 - PROGRESS: at 67.23% examples, 324459 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:40,236 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:40,245 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:40,253 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:40,257 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:40,257 : INFO : EPOCH - 5 : training on 2724082 raw words (962284 effective words) took 2.9s, 336649 effective words/s\n",
      "2018-04-16 19:33:41,265 : INFO : EPOCH 6 - PROGRESS: at 39.38% examples, 382592 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:42,274 : INFO : EPOCH 6 - PROGRESS: at 83.95% examples, 402170 words/s, in_qsize 0, out_qsize 0\n",
      "2018-04-16 19:33:42,627 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:42,635 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:42,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:42,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:42,642 : INFO : EPOCH - 6 : training on 2724082 raw words (962529 effective words) took 2.4s, 404004 effective words/s\n",
      "2018-04-16 19:33:43,659 : INFO : EPOCH 7 - PROGRESS: at 37.60% examples, 361950 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:44,665 : INFO : EPOCH 7 - PROGRESS: at 79.90% examples, 381838 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 19:33:45,324 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:45,330 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:45,334 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:45,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:45,337 : INFO : EPOCH - 7 : training on 2724082 raw words (962745 effective words) took 2.7s, 357490 effective words/s\n",
      "2018-04-16 19:33:46,343 : INFO : EPOCH 8 - PROGRESS: at 40.81% examples, 397601 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 19:33:47,345 : INFO : EPOCH 8 - PROGRESS: at 83.95% examples, 404137 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 19:33:47,694 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:47,708 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:47,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:47,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:47,715 : INFO : EPOCH - 8 : training on 2724082 raw words (962505 effective words) took 2.4s, 405227 effective words/s\n",
      "2018-04-16 19:33:48,725 : INFO : EPOCH 9 - PROGRESS: at 40.81% examples, 397585 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:49,736 : INFO : EPOCH 9 - PROGRESS: at 82.48% examples, 395514 words/s, in_qsize 3, out_qsize 1\n",
      "2018-04-16 19:33:50,107 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:50,111 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:50,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:50,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:50,122 : INFO : EPOCH - 9 : training on 2724082 raw words (962904 effective words) took 2.4s, 401119 effective words/s\n",
      "2018-04-16 19:33:51,125 : INFO : EPOCH 10 - PROGRESS: at 31.75% examples, 308943 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 19:33:52,128 : INFO : EPOCH 10 - PROGRESS: at 74.31% examples, 358700 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:52,703 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:52,714 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:52,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:52,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:52,723 : INFO : EPOCH - 10 : training on 2724082 raw words (962309 effective words) took 2.6s, 370398 effective words/s\n",
      "2018-04-16 19:33:53,727 : INFO : EPOCH 11 - PROGRESS: at 40.45% examples, 394291 words/s, in_qsize 8, out_qsize 1\n",
      "2018-04-16 19:33:54,733 : INFO : EPOCH 11 - PROGRESS: at 83.96% examples, 403421 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:33:55,070 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:55,076 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:55,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:55,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:55,085 : INFO : EPOCH - 11 : training on 2724082 raw words (962386 effective words) took 2.4s, 407840 effective words/s\n",
      "2018-04-16 19:33:56,102 : INFO : EPOCH 12 - PROGRESS: at 31.03% examples, 298233 words/s, in_qsize 3, out_qsize 1\n",
      "2018-04-16 19:33:57,109 : INFO : EPOCH 12 - PROGRESS: at 74.69% examples, 357562 words/s, in_qsize 5, out_qsize 1\n",
      "2018-04-16 19:33:57,666 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:33:57,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:33:57,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:33:57,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:33:57,679 : INFO : EPOCH - 12 : training on 2724082 raw words (963546 effective words) took 2.6s, 371796 effective words/s\n",
      "2018-04-16 19:33:58,684 : INFO : EPOCH 13 - PROGRESS: at 40.81% examples, 398041 words/s, in_qsize 6, out_qsize 1\n",
      "2018-04-16 19:33:59,690 : INFO : EPOCH 13 - PROGRESS: at 84.33% examples, 404843 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:00,020 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:00,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:00,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:00,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:00,029 : INFO : EPOCH - 13 : training on 2724082 raw words (962175 effective words) took 2.3s, 409864 effective words/s\n",
      "2018-04-16 19:34:01,045 : INFO : EPOCH 14 - PROGRESS: at 41.17% examples, 397863 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:02,050 : INFO : EPOCH 14 - PROGRESS: at 75.06% examples, 360101 words/s, in_qsize 4, out_qsize 0\n",
      "2018-04-16 19:34:02,593 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:02,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:02,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:02,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:02,600 : INFO : EPOCH - 14 : training on 2724082 raw words (963643 effective words) took 2.6s, 375162 effective words/s\n",
      "2018-04-16 19:34:03,622 : INFO : EPOCH 15 - PROGRESS: at 40.81% examples, 391853 words/s, in_qsize 7, out_qsize 1\n",
      "2018-04-16 19:34:04,633 : INFO : EPOCH 15 - PROGRESS: at 83.22% examples, 395885 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:05,004 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:05,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:05,012 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:05,013 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:05,013 : INFO : EPOCH - 15 : training on 2724082 raw words (963039 effective words) took 2.4s, 399556 effective words/s\n",
      "2018-04-16 19:34:06,028 : INFO : EPOCH 16 - PROGRESS: at 39.74% examples, 384063 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:07,053 : INFO : EPOCH 16 - PROGRESS: at 82.11% examples, 389204 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:07,637 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:07,638 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:07,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:07,644 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:07,644 : INFO : EPOCH - 16 : training on 2724082 raw words (963064 effective words) took 2.6s, 366353 effective words/s\n",
      "2018-04-16 19:34:08,654 : INFO : EPOCH 17 - PROGRESS: at 39.74% examples, 385715 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:09,662 : INFO : EPOCH 17 - PROGRESS: at 82.85% examples, 396932 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:10,028 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:10,034 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:10,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:10,040 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:10,041 : INFO : EPOCH - 17 : training on 2724082 raw words (963008 effective words) took 2.4s, 402299 effective words/s\n",
      "2018-04-16 19:34:11,049 : INFO : EPOCH 18 - PROGRESS: at 40.45% examples, 393304 words/s, in_qsize 5, out_qsize 1\n",
      "2018-04-16 19:34:12,054 : INFO : EPOCH 18 - PROGRESS: at 83.95% examples, 402629 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 19:34:12,397 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:12,401 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 19:34:12,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:12,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:12,415 : INFO : EPOCH - 18 : training on 2724082 raw words (961574 effective words) took 2.4s, 405636 effective words/s\n",
      "2018-04-16 19:34:13,425 : INFO : EPOCH 19 - PROGRESS: at 31.03% examples, 300370 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:14,433 : INFO : EPOCH 19 - PROGRESS: at 73.58% examples, 353424 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 19:34:14,992 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:14,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:14,997 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:15,001 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:15,002 : INFO : EPOCH - 19 : training on 2724082 raw words (962502 effective words) took 2.6s, 372533 effective words/s\n",
      "2018-04-16 19:34:16,009 : INFO : EPOCH 20 - PROGRESS: at 40.81% examples, 397151 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 19:34:17,015 : INFO : EPOCH 20 - PROGRESS: at 82.85% examples, 397759 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:17,379 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:17,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:17,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:17,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:17,395 : INFO : EPOCH - 20 : training on 2724082 raw words (962770 effective words) took 2.4s, 402732 effective words/s\n",
      "2018-04-16 19:34:18,453 : INFO : EPOCH 21 - PROGRESS: at 33.21% examples, 306551 words/s, in_qsize 8, out_qsize 1\n",
      "2018-04-16 19:34:19,453 : INFO : EPOCH 21 - PROGRESS: at 76.18% examples, 358251 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 19:34:20,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:20,017 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:20,023 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:20,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:20,026 : INFO : EPOCH - 21 : training on 2724082 raw words (962174 effective words) took 2.6s, 365909 effective words/s\n",
      "2018-04-16 19:34:21,030 : INFO : EPOCH 22 - PROGRESS: at 40.10% examples, 391543 words/s, in_qsize 6, out_qsize 0\n",
      "2018-04-16 19:34:22,037 : INFO : EPOCH 22 - PROGRESS: at 83.95% examples, 403727 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:22,377 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:22,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:22,388 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:22,389 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:22,390 : INFO : EPOCH - 22 : training on 2724082 raw words (962354 effective words) took 2.4s, 407703 effective words/s\n",
      "2018-04-16 19:34:23,413 : INFO : EPOCH 23 - PROGRESS: at 40.46% examples, 387769 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:24,423 : INFO : EPOCH 23 - PROGRESS: at 73.58% examples, 350828 words/s, in_qsize 0, out_qsize 1\n",
      "2018-04-16 19:34:24,999 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:25,003 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:25,009 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:25,013 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:25,014 : INFO : EPOCH - 23 : training on 2724082 raw words (962713 effective words) took 2.6s, 367215 effective words/s\n",
      "2018-04-16 19:34:26,021 : INFO : EPOCH 24 - PROGRESS: at 44.06% examples, 430199 words/s, in_qsize 0, out_qsize 0\n",
      "2018-04-16 19:34:27,021 : INFO : EPOCH 24 - PROGRESS: at 88.35% examples, 425396 words/s, in_qsize 5, out_qsize 0\n",
      "2018-04-16 19:34:27,256 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:27,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:27,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:27,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:27,267 : INFO : EPOCH - 24 : training on 2724082 raw words (962231 effective words) took 2.2s, 427936 effective words/s\n",
      "2018-04-16 19:34:28,277 : INFO : EPOCH 25 - PROGRESS: at 40.10% examples, 389021 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:29,285 : INFO : EPOCH 25 - PROGRESS: at 83.58% examples, 400399 words/s, in_qsize 7, out_qsize 0\n",
      "2018-04-16 19:34:29,637 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-16 19:34:29,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-16 19:34:29,643 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-16 19:34:29,650 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-16 19:34:29,651 : INFO : EPOCH - 25 : training on 2724082 raw words (962763 effective words) took 2.4s, 404441 effective words/s\n",
      "2018-04-16 19:34:29,651 : INFO : training on a 68102050 raw words (24066077 effective words) took 64.0s, 375901 effective words/s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = MySentences(questions_folder_name, rows=num_question_pairs)\n",
    "word2vec_model = gensim.models.Word2Vec(sentences, size=300, window=5, alpha=0.025, min_alpha=.0001, \n",
    "                                        min_count=1, sample=5e-5, workers=cores, negative=5, \n",
    "                                        sg=1, iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences2 = MySentences(questions_folder_name2, rows=num_question_pairs)\n",
    "word2vec_model2 = gensim.models.Word2Vec(sentences2, size=300, window=5, alpha=0.025, min_alpha=.0001, \n",
    "                                        min_count=1, sample=5e-5, workers=cores, negative=5, \n",
    "                                        sg=1, iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "q1_word2vecs = []\n",
    "q2_word2vecs = []\n",
    "is_dup_word2vecs = []\n",
    "\n",
    "q1_iterator = OneFileSentences(questions_folder_name + \"/\" + q1_file_name, rows=num_question_pairs)\n",
    "q2_iterator = OneFileSentences(questions_folder_name + \"/\" + q2_file_name, rows=num_question_pairs)\n",
    "\n",
    "for q1_sentence, q2_sentence in zip(q1_iterator, q2_iterator):\n",
    "    q1_vec = qu.make_question_vectors(word2vec_model, q1_sentence)\n",
    "    q2_vec = qu.make_question_vectors(word2vec_model, q2_sentence) \n",
    "    q1_word2vecs.append(q1_vec)\n",
    "    q2_word2vecs.append(q2_vec)\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class)):\n",
    "    is_dup_word2vecs.append(doc_names_and_duplicate_class[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "q1_word2vecs2 = []\n",
    "q2_word2vecs2 = []\n",
    "is_dup_word2vecs2 = []\n",
    "\n",
    "q1_iterator2 = OneFileSentences(questions_folder_name2 + \"/\" + q1_file_name2, rows=num_question_pairs)\n",
    "q2_iterator2 = OneFileSentences(questions_folder_name2 + \"/\" + q2_file_name2, rows=num_question_pairs)\n",
    "\n",
    "for q1_sentence2, q2_sentence2 in zip(q1_iterator2, q2_iterator2):\n",
    "    q1_vec2 = qu.make_question_vectors(word2vec_model2, q1_sentence2)\n",
    "    q2_vec2 = qu.make_question_vectors(word2vec_model2, q2_sentence2) \n",
    "    q1_word2vecs.append(q1_vec2)\n",
    "    q2_word2vecs.append(q2_vec2)\n",
    "\n",
    "for i in range(len(doc_names_and_duplicate_class2)):\n",
    "    is_dup_word2vecs.append(doc_names_and_duplicate_class2[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_1_w2v = np.array(q1_word2vecs)\n",
    "X_2_w2v = np.array(q2_word2vecs)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "num_classes = 2\n",
    "\n",
    "y_w2v = np_utils.to_categorical(np.array(is_dup_word2vecs), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_1_w2v2 = np.array(q1_word2vecs2)\n",
    "X_2_w2v2 = np.array(q2_word2vecs2)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "num_classes = 2\n",
    "\n",
    "y_w2v = np_utils.to_categorical(np.array(is_dup_word2vecs), num_classes)\n",
    "y_w2v2 = np_utils.to_categorical(np.array(is_dup_word2vecs2), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 19:37:51,635 : INFO : loading projection weights from /Users/megoconnell/Documents/Courses/Independent Study/RNNs/GoogleNews-vectors-negative300.bin\n",
      "2018-04-16 19:39:07,418 : INFO : loaded (3000000, 300) matrix from /Users/megoconnell/Documents/Courses/Independent Study/RNNs/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "Google_word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(google_model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "q1_google_word2vecs = []\n",
    "q2_google_word2vecs = []\n",
    "is_dup_google = []\n",
    "\n",
    "q1_iterator = OneFileSentences(questions_folder_name + \"/\" + q1_file_name, rows=num_question_pairs)\n",
    "q2_iterator = OneFileSentences(questions_folder_name + \"/\" + q2_file_name, rows=num_question_pairs)\n",
    "\n",
    "for q1_sentence, q2_sentence in zip(q1_iterator, q2_iterator):\n",
    "    q1_vec = qu.make_question_vectors(Google_word2vec_model, q1_sentence)\n",
    "    q2_vec = qu.make_question_vectors(Google_word2vec_model, q2_sentence) \n",
    "    q1_google_word2vecs.append(q1_vec)\n",
    "    q2_google_word2vecs.append(q2_vec)\n",
    "    \n",
    "for i in range(len(doc_names_and_duplicate_class)):\n",
    "    is_dup_google.append(doc_names_and_duplicate_class[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "q1_google_word2vecs2 = []\n",
    "q2_google_word2vecs2 = []\n",
    "is_dup_google2 = []\n",
    "\n",
    "q1_iterator2 = OneFileSentences(questions_folder_name2 + \"/\" + q1_file_name2, rows=num_question_pairs)\n",
    "q2_iterator2 = OneFileSentences(questions_folder_name2 + \"/\" + q2_file_name2, rows=num_question_pairs)\n",
    "\n",
    "for q1_sentence2, q2_sentence2 in zip(q1_iterator2, q2_iterator2):\n",
    "    q1_vec2 = qu.make_question_vectors(Google_word2vec_model2, q1_sentence2)\n",
    "    q2_vec2 = qu.make_question_vectors(Google_word2vec_model2, q2_sentence2) \n",
    "    q1_google_word2vecs2.append(q1_vec2)\n",
    "    q2_google_word2vecs2.append(q2_vec2)\n",
    "    \n",
    "for i in range(len(doc_names_and_duplicate_class2)):\n",
    "    is_dup_google2.append(doc_names_and_duplicate_class2[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_G_w2v = np.array(q1_word2vecs)\n",
    "X_2_G_w2v = np.array(q2_word2vecs)\n",
    "X_1_G_w2v2 = np.array(q1_word2vecs2)\n",
    "X_2_G_w2v2 = np.array(q2_word2vecs2)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "num_classes = 2\n",
    "\n",
    "y_G_w2v = np_utils.to_categorical(np.array(is_dup_google), num_classes)\n",
    "y_G_w2v2 = np_utils.to_categorical2(np.array(is_dup_google2), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the generic model names X_1, X_2, y to the values from model we want \n",
    "\n",
    "\"\"\"\n",
    "Model matrices: \n",
    "\n",
    "\"doc2vec vectors:\" DONE\n",
    "\n",
    "X_1 = X_1_d2v\n",
    "X_2 = X_2_d2v\n",
    "y = y_d2v\n",
    "\n",
    "\"doc2vec using only word2vec word averages:\"\n",
    "\n",
    "X_1 = X_1_d_w2v\n",
    "X_2 = X_2_d_w2v\n",
    "y = y_d_w2v\n",
    "\n",
    "\"word2vec on questions alone:\" DONE \n",
    "\n",
    "X_1 = X_1_w2v\n",
    "X_2 = X_2_w2v\n",
    "y = y_w2v\n",
    "\n",
    "\"word2vec on Google News:\" DONE\n",
    "\n",
    "X_1 = X_1_G_w2v\n",
    "X_2 = X_2_G_w2v\n",
    "y = y_G_w2v\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"doc2vec using only word2vec word averages:\"\n",
    "\n",
    "X_1 = X_1_d_w2v\n",
    "X_2 = X_2_d_w2v\n",
    "y = y_d_w2v\n",
    "\n",
    "TX_1 = X_1_d_w2v2\n",
    "TX_2 = X_2_d_w2v2\n",
    "Ty = y_d_w2v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since vectors already in random order, train/test split can be done by simple indexing without shuffle\n",
    "# if additional shuffle is desired can be done like this (the random state makes results reproducible; \n",
    "# change random_state for different shuffle)\n",
    "#\n",
    "# from sklearn.utils import shuffle\n",
    "# X_1, X_2, y = shuffle(X_1, X_2, y, random_state=1)\n",
    "#\n",
    "# and then execute code below\n",
    "\n",
    "test_portion = 0.2\n",
    "split_index = int((1-test_portion)*len(X_1))\n",
    "X_1_train, X_2_train = X_1, X_2\n",
    "X_1_test, X_2_test = TX_1, TX_2\n",
    "y_train = y\n",
    "y_test = Ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Merge, Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "q1_branch = Sequential()\n",
    "q1_branch.add(Dense(1000, input_shape=(300,), activation='relu'))\n",
    "q1_branch.add(Dropout(0.2))\n",
    "\n",
    "q2_branch = Sequential()\n",
    "q2_branch.add(Dense(1000, input_shape=(300,), activation='relu'))\n",
    "q2_branch.add(Dropout(0.2))\n",
    "\n",
    "merged = Merge([q1_branch, q2_branch], mode='concat')\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)\n",
    "final_model.add(Dense(500, activation='relu'))\n",
    "final_model.add(Dropout(0.2))\n",
    "final_model.add(Dense(500, activation='relu'))\n",
    "final_model.add(Dropout(0.2))\n",
    "final_model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model - accuracy will be metrix we optimize for\n",
    "final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80339 samples, validate on 20085 samples\n",
      "Epoch 1/25\n",
      "  500/80339 [..............................] - ETA: 28s - loss: 0.2020 - acc: 0.9260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80339/80339 [==============================] - 31s 382us/step - loss: 0.2002 - acc: 0.9204 - val_loss: 0.1750 - val_acc: 0.9314\n",
      "Epoch 2/25\n",
      "80339/80339 [==============================] - 31s 380us/step - loss: 0.1428 - acc: 0.9438 - val_loss: 0.1595 - val_acc: 0.9396\n",
      "Epoch 3/25\n",
      "80339/80339 [==============================] - 31s 389us/step - loss: 0.1109 - acc: 0.9572 - val_loss: 0.1602 - val_acc: 0.9392\n",
      "Epoch 4/25\n",
      "80339/80339 [==============================] - 32s 404us/step - loss: 0.0898 - acc: 0.9661 - val_loss: 0.1662 - val_acc: 0.9436\n",
      "Epoch 5/25\n",
      "80339/80339 [==============================] - 31s 381us/step - loss: 0.0740 - acc: 0.9733 - val_loss: 0.1468 - val_acc: 0.9486\n",
      "Epoch 6/25\n",
      "80339/80339 [==============================] - 25s 315us/step - loss: 0.0628 - acc: 0.9769 - val_loss: 0.1480 - val_acc: 0.9503\n",
      "Epoch 7/25\n",
      "80339/80339 [==============================] - 25s 307us/step - loss: 0.0554 - acc: 0.9802 - val_loss: 0.1465 - val_acc: 0.9521\n",
      "Epoch 8/25\n",
      "80339/80339 [==============================] - 25s 311us/step - loss: 0.0499 - acc: 0.9820 - val_loss: 0.1498 - val_acc: 0.9523\n",
      "Epoch 9/25\n",
      "80339/80339 [==============================] - 30s 374us/step - loss: 0.0457 - acc: 0.9833 - val_loss: 0.1456 - val_acc: 0.9533\n",
      "Epoch 10/25\n",
      "80339/80339 [==============================] - 31s 382us/step - loss: 0.0395 - acc: 0.9857 - val_loss: 0.1672 - val_acc: 0.9533\n",
      "Epoch 11/25\n",
      "80339/80339 [==============================] - 30s 376us/step - loss: 0.0380 - acc: 0.9863 - val_loss: 0.1546 - val_acc: 0.9545\n",
      "Epoch 12/25\n",
      "80339/80339 [==============================] - 29s 361us/step - loss: 0.0356 - acc: 0.9868 - val_loss: 0.1508 - val_acc: 0.9544\n",
      "Epoch 13/25\n",
      "80339/80339 [==============================] - 32s 393us/step - loss: 0.0329 - acc: 0.9881 - val_loss: 0.1540 - val_acc: 0.9591\n",
      "Epoch 14/25\n",
      "80339/80339 [==============================] - 30s 376us/step - loss: 0.0312 - acc: 0.9892 - val_loss: 0.1704 - val_acc: 0.9557\n",
      "Epoch 15/25\n",
      "80339/80339 [==============================] - 26s 325us/step - loss: 0.0283 - acc: 0.9901 - val_loss: 0.1583 - val_acc: 0.9542\n",
      "Epoch 16/25\n",
      "80339/80339 [==============================] - 26s 321us/step - loss: 0.0283 - acc: 0.9904 - val_loss: 0.1728 - val_acc: 0.9550\n",
      "Epoch 17/25\n",
      "80339/80339 [==============================] - 28s 347us/step - loss: 0.0267 - acc: 0.9906 - val_loss: 0.1646 - val_acc: 0.9596\n",
      "Epoch 18/25\n",
      "80339/80339 [==============================] - 30s 376us/step - loss: 0.0274 - acc: 0.9905 - val_loss: 0.1604 - val_acc: 0.9607\n",
      "Epoch 19/25\n",
      "80339/80339 [==============================] - 30s 377us/step - loss: 0.0241 - acc: 0.9915 - val_loss: 0.1468 - val_acc: 0.9606\n",
      "Epoch 20/25\n",
      "80339/80339 [==============================] - 30s 378us/step - loss: 0.0237 - acc: 0.9921 - val_loss: 0.1796 - val_acc: 0.9572\n",
      "Epoch 21/25\n",
      "80339/80339 [==============================] - 31s 381us/step - loss: 0.0220 - acc: 0.9925 - val_loss: 0.1702 - val_acc: 0.9605\n",
      "Epoch 22/25\n",
      "80339/80339 [==============================] - 31s 383us/step - loss: 0.0227 - acc: 0.9920 - val_loss: 0.1757 - val_acc: 0.9561\n",
      "Epoch 23/25\n",
      "80339/80339 [==============================] - 31s 386us/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.1754 - val_acc: 0.9602\n",
      "Epoch 24/25\n",
      "80339/80339 [==============================] - 31s 382us/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.1637 - val_acc: 0.9595\n",
      "Epoch 25/25\n",
      "80339/80339 [==============================] - 31s 388us/step - loss: 0.0202 - acc: 0.9929 - val_loss: 0.1739 - val_acc: 0.9586\n"
     ]
    }
   ],
   "source": [
    "# train model - the history output is object that can be queried for model properties - see Keras documentation\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "history = final_model.fit([X_1_train, X_2_train], y_train, \n",
    "                   batch_size=100, nb_epoch=25,\n",
    "                   verbose=1, validation_data=([X_1_test, X_2_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-16 20:10:33,239 : INFO : loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "2018-04-16 20:11:59,050 : INFO : loaded (3000000, 300) matrix from GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megoconnell/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "all_words = [word for sentence in data['question1'] for word in re.split('\\W', sentence)]\n",
    "unique = (set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = unique\n",
    "c = []\n",
    "for word in a:\n",
    "    if word in word_vectors.vocab:\n",
    "        c.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(w):\n",
    "    return words.loc[w].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "for word in c:\n",
    "    vword = model[word]\n",
    "    vector = {word : vword }\n",
    "    dict1.update(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = []\n",
    "for word, vector in dict1.items():    # for name, age in list.items():  (for Python 3.x)\n",
    "    if np.any(vector == X_1_train):\n",
    "        list.append(word)\n",
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x382524d68>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x38262c908>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9586258401792382\n",
      "Precision: 0.9405\n",
      "Recall: 0.9787\n",
      "F1 Score: 0.9592\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "prediction_probs = final_model.predict([X_1_test, X_2_test])\n",
    "# predictions is list of definite [0,1] predictions as extracted from predicted probabilities\n",
    "predictions = [np.array([1,0]) if x[0]>x[1] else np.array([0,1]) for x in prediction_probs]\n",
    "\n",
    "# convert predictions and y_test back into regular list of 0s and 1s for sklearn functions\n",
    "predictions_labels, y_test_labels = [], []\n",
    "for i in range(len(y_test)):\n",
    "    if predictions[i][1] == 1: \n",
    "        predictions_labels.append(1)\n",
    "    else: \n",
    "        predictions_labels.append(0)\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i][1] == 1: \n",
    "        y_test_labels.append(1)\n",
    "    else: \n",
    "        y_test_labels.append(0)\n",
    "\n",
    "prfs = precision_recall_fscore_support(y_test_labels, predictions_labels, average='binary')\n",
    "acc = accuracy_score(y_test_labels, predictions_labels)\n",
    "print (\"Accuracy:\", acc)\n",
    "print (\"Precision:\", round(prfs[0], 4))\n",
    "print (\"Recall:\", round(prfs[1], 4))\n",
    "print (\"F1 Score:\", round(prfs[2], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save val_acc and val_loss for each model to plot later\n",
    "# can then plot the three model val_acc and val_loss together to see how they behave\n",
    "\n",
    "# for each model there is list that contains acc, val_acc, loss, val_loss \n",
    "# (these mean model train accuracy, model test accuracy, model train loss, and model test loss)\n",
    "\n",
    "doc2vec_val = {\"acc\": history.history[\"acc\"], \n",
    "               \"val_acc\": history.history[\"val_acc\"], \n",
    "               \"loss\": history.history[\"loss\"], \n",
    "               \"val_loss\": history.history[\"val_loss\"], \n",
    "               \"accuracy\": acc, \n",
    "               \"precision\": round(prfs[0], 4), \n",
    "               \"recall\": round(prfs[1], 4), \n",
    "               \"F1\": round(prfs[2], 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_words_val = {\"acc\": history.history[\"acc\"], \n",
    "               \"val_acc\": history.history[\"val_acc\"], \n",
    "               \"loss\": history.history[\"loss\"], \n",
    "               \"val_loss\": history.history[\"val_loss\"], \n",
    "               \"accuracy\": acc, \n",
    "               \"precision\": round(prfs[0], 4), \n",
    "               \"recall\": round(prfs[1], 4), \n",
    "               \"F1\": round(prfs[2], 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_val = {\"acc\": history.history[\"acc\"], \n",
    "               \"val_acc\": history.history[\"val_acc\"], \n",
    "               \"loss\": history.history[\"loss\"], \n",
    "               \"val_loss\": history.history[\"val_loss\"], \n",
    "               \"accuracy\": acc, \n",
    "               \"precision\": round(prfs[0], 4), \n",
    "               \"recall\": round(prfs[1], 4), \n",
    "               \"F1\": round(prfs[2], 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google_word2vec_val = {\"acc\": history.history[\"acc\"], \n",
    "                       \"val_acc\": history.history[\"val_acc\"], \n",
    "                       \"loss\": history.history[\"loss\"], \n",
    "                       \"val_loss\": history.history[\"val_loss\"], \n",
    "                       \"accuracy\": acc, \n",
    "                       \"precision\": round(prfs[0], 4), \n",
    "                       \"recall\": round(prfs[1], 4), \n",
    "                       \"F1\": round(prfs[2], 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of current model and model evaluation dictionary to use \n",
    "model_tag = \"doc2vec_words\"\n",
    "current_val_dict = doc2vec_words_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = model_tag + \"_acc_loss.csv\"\n",
    "text_file_name = model_tag + \"_acc_precision_recall.txt\"\n",
    "\n",
    "model_dataframe = pd.DataFrame({\"acc\": history.history[\"acc\"], \n",
    "               \"val_acc\": history.history[\"val_acc\"], \n",
    "               \"loss\": history.history[\"loss\"], \n",
    "               \"val_loss\": history.history[\"val_loss\"]})\n",
    "\n",
    "model_dataframe.to_csv(csv_file_name, index=False)\n",
    "\n",
    "with open(text_file_name, \"w\") as text_file:\n",
    "    text_file.write(\"Accuracy: {}\\n\".format(current_val_dict[\"accuracy\"]))\n",
    "    text_file.write(\"Precision: {}\\n\".format(current_val_dict[\"precision\"]))\n",
    "    text_file.write(\"Recall: {}\\n\".format(current_val_dict[\"recall\"]))\n",
    "    text_file.write(\"F1: {}\".format(current_val_dict[\"F1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc2vec_words_acc_loss.csv'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec_df =  pd.read_csv(\"doc2vec_acc_loss.csv\")\n",
    "doc2vec_words_df = pd.read_csv(\"doc2vec_words_acc_loss.csv\")\n",
    "#word2vec_skipgram_df = pd.read_csv(\"question_vector_model_evaluation/word2vec_skipgram/word2vec_skipgram_acc_loss.csv\")\n",
    "#google_news_word2vec_df = pd.read_csv(\"question_vector_model_evaluation/google_news_word2vec/google_news_word2vec_acc_loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.920400</td>\n",
       "      <td>0.200232</td>\n",
       "      <td>0.931392</td>\n",
       "      <td>0.174983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.943838</td>\n",
       "      <td>0.142836</td>\n",
       "      <td>0.939607</td>\n",
       "      <td>0.159541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957169</td>\n",
       "      <td>0.110867</td>\n",
       "      <td>0.939208</td>\n",
       "      <td>0.160218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966119</td>\n",
       "      <td>0.089807</td>\n",
       "      <td>0.943590</td>\n",
       "      <td>0.166232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973251</td>\n",
       "      <td>0.073977</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>0.146848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc      loss   val_acc  val_loss\n",
       "0  0.920400  0.200232  0.931392  0.174983\n",
       "1  0.943838  0.142836  0.939607  0.159541\n",
       "2  0.957169  0.110867  0.939208  0.160218\n",
       "3  0.966119  0.089807  0.943590  0.166232\n",
       "4  0.973251  0.073977  0.948569  0.146848"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc2vec_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-462bdd16daa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc2vec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc2vec_words_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_skipgram_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_news_word2vec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc2vec_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "plt.plot(doc2vec_df[\"val_acc\"].values)\n",
    "plt.plot(doc2vec_words_df[\"val_acc\"].values)\n",
    "plt.plot(word2vec_skipgram_df[\"val_acc\"].values)\n",
    "plt.plot(google_news_word2vec_df[\"val_acc\"].values)\n",
    "plt.title('Model Validation Accuracy', fontsize=50)\n",
    "plt.ylabel('validattion accuracy', fontsize=40)\n",
    "plt.xlabel('training epoch', fontsize=40)\n",
    "plt.legend(['doc2vec', 'doc2vec_words', 'word2vec_skipgram', 'google_news'], loc='upper left', prop={'size':30})\n",
    "plt.tick_params(labelsize=35)\n",
    "plt.savefig('val_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.plot(doc2vec_df[\"val_loss\"].values)\n",
    "plt.plot(doc2vec_words_df[\"val_loss\"].values)\n",
    "plt.plot(word2vec_skipgram_df[\"val_loss\"].values)\n",
    "plt.plot(google_news_word2vec_df[\"val_loss\"].values)\n",
    "plt.title('Model Validation Loss', fontsize=50)\n",
    "plt.ylabel('validated loss', fontsize=40)\n",
    "plt.xlabel('epoch', fontsize=40)\n",
    "plt.legend(['doc2vec', 'doc2vec_words', 'word2vec_skipgram', 'google_news'], loc='upper left', prop={'size':30})\n",
    "plt.tick_params(labelsize=35)\n",
    "plt.savefig('val_loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
